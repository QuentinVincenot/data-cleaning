{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "This notebook aims to show a subset of methods used to clean datasets before performing further analysis and visualisations.\n",
    "\n",
    "It is splitted in 2 parts : the dataset generation, and the data cleaning process.  \n",
    "- **Dataset generation** permits to parametrise the dataset generation.\n",
    "- **Data cleaning process** showcases the different methods explained in the README."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_generation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Category</th>\n",
       "      <th>Height</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Date</th>\n",
       "      <th>Country</th>\n",
       "      <th>Email</th>\n",
       "      <th>Strange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Special</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93000</td>\n",
       "      <td>2 1983-6</td>\n",
       "      <td>USA</td>\n",
       "      <td>9B1Ut.SkoZR@laposte.net</td>\n",
       "      <td>X7LLSoUSlq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Special</td>\n",
       "      <td>1.57</td>\n",
       "      <td>88000</td>\n",
       "      <td>3 1969-26</td>\n",
       "      <td>USA</td>\n",
       "      <td>RMjxg.W3Yep@gmail.com</td>\n",
       "      <td>BwBItj9uZs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John</td>\n",
       "      <td>NaN</td>\n",
       "      <td>null</td>\n",
       "      <td>2.01</td>\n",
       "      <td>46000</td>\n",
       "      <td>3 1999-23</td>\n",
       "      <td>USA</td>\n",
       "      <td>QgcY2.84ydd@hotmail.com</td>\n",
       "      <td>2yBy6xRMuO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1.62</td>\n",
       "      <td>68000</td>\n",
       "      <td>6 1980-27</td>\n",
       "      <td>SAF</td>\n",
       "      <td>QhesO.0ZHiH@laposte.net</td>\n",
       "      <td>bfmkc5TPVF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thomas</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Special</td>\n",
       "      <td>2.10</td>\n",
       "      <td>124000</td>\n",
       "      <td>11 1980-27</td>\n",
       "      <td>USA</td>\n",
       "      <td>2EaDA.nFget@hotmail.com</td>\n",
       "      <td>J56iJ77KGl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Patricia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1.55</td>\n",
       "      <td>68000</td>\n",
       "      <td>3 1982-26</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>r2MGQ.0fip0@gmail.com</td>\n",
       "      <td>W0DDm0hZlH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Joseph</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Special</td>\n",
       "      <td>1.58</td>\n",
       "      <td>41000</td>\n",
       "      <td>9 2010-13</td>\n",
       "      <td>France</td>\n",
       "      <td>Q8jBw.saull@laposte.net</td>\n",
       "      <td>MilCa8RXE8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Susan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.60</td>\n",
       "      <td>38000</td>\n",
       "      <td>11 2000-14</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>yIDdk.YWZMi@gmail.com</td>\n",
       "      <td>UaBaEle95K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>William</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Classic</td>\n",
       "      <td>1.89</td>\n",
       "      <td>85000</td>\n",
       "      <td>10 2017-19</td>\n",
       "      <td>China</td>\n",
       "      <td>QA9QV.oB7s6@weneverknow.com</td>\n",
       "      <td>GfSproq9u0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Elizabeth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Special</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138000</td>\n",
       "      <td>5 2013-22</td>\n",
       "      <td>USA</td>\n",
       "      <td>K2cKv.N5ytE@gmail.com</td>\n",
       "      <td>X4KqTtiVFV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name  Missing Category  Height  Salary        Date Country  \\\n",
       "0        NaN      NaN  Special     NaN   93000    2 1983-6     USA   \n",
       "1        NaN      NaN  Special    1.57   88000   3 1969-26     USA   \n",
       "2       John      NaN     null    2.01   46000   3 1999-23     USA   \n",
       "3        NaN      NaN  Regular    1.62   68000   6 1980-27     SAF   \n",
       "4     Thomas     56.0  Special    2.10  124000  11 1980-27     USA   \n",
       "5   Patricia      NaN  Regular    1.55   68000   3 1982-26  Brasil   \n",
       "6     Joseph      NaN  Special    1.58   41000   9 2010-13  France   \n",
       "7      Susan      NaN      NaN    1.60   38000  11 2000-14  Brasil   \n",
       "8    William      NaN  Classic    1.89   85000  10 2017-19   China   \n",
       "9  Elizabeth      NaN  Special     NaN  138000   5 2013-22     USA   \n",
       "\n",
       "                         Email     Strange  \n",
       "0      9B1Ut.SkoZR@laposte.net  X7LLSoUSlq  \n",
       "1        RMjxg.W3Yep@gmail.com  BwBItj9uZs  \n",
       "2      QgcY2.84ydd@hotmail.com  2yBy6xRMuO  \n",
       "3      QhesO.0ZHiH@laposte.net  bfmkc5TPVF  \n",
       "4      2EaDA.nFget@hotmail.com  J56iJ77KGl  \n",
       "5        r2MGQ.0fip0@gmail.com  W0DDm0hZlH  \n",
       "6      Q8jBw.saull@laposte.net  MilCa8RXE8  \n",
       "7        yIDdk.YWZMi@gmail.com  UaBaEle95K  \n",
       "8  QA9QV.oB7s6@weneverknow.com  GfSproq9u0  \n",
       "9        K2cKv.N5ytE@gmail.com  X4KqTtiVFV  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = generate_dataset(length=500, name_errors=0.2, missing_errors=0.8, category_errors=0.25,\n",
    "                             height_errors=0.15, salary_errors=0.07)\n",
    "dataframe.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a/ Strange feature deletion\n",
    "\n",
    "Sometimes, there are features in your data that seem relatively strange, and in some cases that are really hard to understand or apprehend. They can be useless features, and to avoid wrong interpretations later in your analysis, deleting this strange feature can be an option.\n",
    "\n",
    "In my dataset, I voluntarily created a **Strange** feature, to showcase the ability to prepare your data and continue your analysis on an appropriate perimeter of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Category</th>\n",
       "      <th>Height</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Date</th>\n",
       "      <th>Country</th>\n",
       "      <th>Email</th>\n",
       "      <th>Strange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Special</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93000</td>\n",
       "      <td>2 1983-6</td>\n",
       "      <td>USA</td>\n",
       "      <td>9B1Ut.SkoZR@laposte.net</td>\n",
       "      <td>X7LLSoUSlq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Special</td>\n",
       "      <td>1.57</td>\n",
       "      <td>88000</td>\n",
       "      <td>3 1969-26</td>\n",
       "      <td>USA</td>\n",
       "      <td>RMjxg.W3Yep@gmail.com</td>\n",
       "      <td>BwBItj9uZs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John</td>\n",
       "      <td>NaN</td>\n",
       "      <td>null</td>\n",
       "      <td>2.01</td>\n",
       "      <td>46000</td>\n",
       "      <td>3 1999-23</td>\n",
       "      <td>USA</td>\n",
       "      <td>QgcY2.84ydd@hotmail.com</td>\n",
       "      <td>2yBy6xRMuO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1.62</td>\n",
       "      <td>68000</td>\n",
       "      <td>6 1980-27</td>\n",
       "      <td>SAF</td>\n",
       "      <td>QhesO.0ZHiH@laposte.net</td>\n",
       "      <td>bfmkc5TPVF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thomas</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Special</td>\n",
       "      <td>2.10</td>\n",
       "      <td>124000</td>\n",
       "      <td>11 1980-27</td>\n",
       "      <td>USA</td>\n",
       "      <td>2EaDA.nFget@hotmail.com</td>\n",
       "      <td>J56iJ77KGl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name  Missing Category  Height  Salary        Date Country  \\\n",
       "0     NaN      NaN  Special     NaN   93000    2 1983-6     USA   \n",
       "1     NaN      NaN  Special    1.57   88000   3 1969-26     USA   \n",
       "2    John      NaN     null    2.01   46000   3 1999-23     USA   \n",
       "3     NaN      NaN  Regular    1.62   68000   6 1980-27     SAF   \n",
       "4  Thomas     56.0  Special    2.10  124000  11 1980-27     USA   \n",
       "\n",
       "                     Email     Strange  \n",
       "0  9B1Ut.SkoZR@laposte.net  X7LLSoUSlq  \n",
       "1    RMjxg.W3Yep@gmail.com  BwBItj9uZs  \n",
       "2  QgcY2.84ydd@hotmail.com  2yBy6xRMuO  \n",
       "3  QhesO.0ZHiH@laposte.net  bfmkc5TPVF  \n",
       "4  2EaDA.nFget@hotmail.com  J56iJ77KGl  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the first few lines of the dataset to get a sense of data\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the \"Useless\" feature of the dataset\n",
    "dataframe = dataframe.drop(['Strange'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Category</th>\n",
       "      <th>Height</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Date</th>\n",
       "      <th>Country</th>\n",
       "      <th>Email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Special</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93000</td>\n",
       "      <td>2 1983-6</td>\n",
       "      <td>USA</td>\n",
       "      <td>9B1Ut.SkoZR@laposte.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Special</td>\n",
       "      <td>1.57</td>\n",
       "      <td>88000</td>\n",
       "      <td>3 1969-26</td>\n",
       "      <td>USA</td>\n",
       "      <td>RMjxg.W3Yep@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John</td>\n",
       "      <td>NaN</td>\n",
       "      <td>null</td>\n",
       "      <td>2.01</td>\n",
       "      <td>46000</td>\n",
       "      <td>3 1999-23</td>\n",
       "      <td>USA</td>\n",
       "      <td>QgcY2.84ydd@hotmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1.62</td>\n",
       "      <td>68000</td>\n",
       "      <td>6 1980-27</td>\n",
       "      <td>SAF</td>\n",
       "      <td>QhesO.0ZHiH@laposte.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thomas</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Special</td>\n",
       "      <td>2.10</td>\n",
       "      <td>124000</td>\n",
       "      <td>11 1980-27</td>\n",
       "      <td>USA</td>\n",
       "      <td>2EaDA.nFget@hotmail.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name  Missing Category  Height  Salary        Date Country  \\\n",
       "0     NaN      NaN  Special     NaN   93000    2 1983-6     USA   \n",
       "1     NaN      NaN  Special    1.57   88000   3 1969-26     USA   \n",
       "2    John      NaN     null    2.01   46000   3 1999-23     USA   \n",
       "3     NaN      NaN  Regular    1.62   68000   6 1980-27     SAF   \n",
       "4  Thomas     56.0  Special    2.10  124000  11 1980-27     USA   \n",
       "\n",
       "                     Email  \n",
       "0  9B1Ut.SkoZR@laposte.net  \n",
       "1    RMjxg.W3Yep@gmail.com  \n",
       "2  QgcY2.84ydd@hotmail.com  \n",
       "3  QhesO.0ZHiH@laposte.net  \n",
       "4  2EaDA.nFget@hotmail.com  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have another look on the data without the useless feature that has been deleted\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After deleting the `Strange` feature I was not interested in, I just have a look at my dataset to check the proper deletion of this feature, and continue my Data Cleaning process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b/ Missing values as a special category\n",
    "\n",
    "In this part, I will study the different values that take the **Category** feature of my dataset.\n",
    "\n",
    "I quickly detect there are a few values that are taken and that represent a missing or an invalid value for the category. Therefore, I want to treat all these different values as a single and unique representation of the missing value concept : affect them all to the same category that I can myself rename `Unknown`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Special    139\n",
       "Classic    120\n",
       "Regular    116\n",
       "???         36\n",
       "null        30\n",
       "NaN         30\n",
       "UNKWN       29\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the different values taken by data for the Category feature\n",
    "dataframe['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace data missing values for the Category feature by a single and dedicated value\n",
    "dataframe['Category'].replace(['NaN', 'null', 'UNKWN', '???'], ['Unknown']*4, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Special    139\n",
       "Unknown    125\n",
       "Classic    120\n",
       "Regular    116\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the different values taken by data for the Category feature, after missing category cleaning process\n",
    "dataframe['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having checked my transformed dataset with this single missing value for the Category feature, I will be able to process this feature later on knowing it can take values I had a glance on (`Classic`, `Regular`, `Special`), or the `Unknown` missing value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c/ Fixing spelling mistakes with known correct values\n",
    "\n",
    "There is a **Country** feature in my dataset that contains a few country names, but some of them are sometimes spelled or written in a strange way. That can totally happen in real life when you collect data from multiple sources and these sources do not have the same software/language references.\n",
    "\n",
    "Then, I will try to understand the misspelled values and replace them by a uniformed writting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "South Africa    83\n",
       "Brasil          79\n",
       "USA             74\n",
       "France          68\n",
       "China           68\n",
       "SAF             31\n",
       "Fr              28\n",
       "brUsil          28\n",
       "uSa             25\n",
       "CHinA           16\n",
       "Name: Country, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the different values taken by data for the Country feature\n",
    "dataframe['Country'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the different values that can take the Country feature, there are few ones that misspelled or abstracted, but we can guess the name of the real country behind it. For example, *Fr* probably means *France*, *CHinA* and *uSa* is of course a misspelling, *SAF* in an abstraction of *South Africa* and *brUsil* is totally a mistake in data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace misspelled and erroneous values for the Country feature by a known correct values\n",
    "dataframe['Country'].replace(['SAF', 'Fr', 'CHinA', 'uSa', 'brUsil'],\n",
    "                             ['South Africa', 'France', 'China', 'USA', 'Brasil'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "South Africa    114\n",
       "Brasil          107\n",
       "USA              99\n",
       "France           96\n",
       "China            84\n",
       "Name: Country, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the different values taken by data for the Country feature, after fixing misspelled values\n",
    "dataframe['Country'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this spellchecking and fixing step of the Data Cleaning process, we now clearly see the different countries involved in the dataset, with no surprising or confusing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d/ Mean filling for missing values\n",
    "\n",
    "The **Height** feature of the dataset miss a few values, but not a large amount. In order to analyse the data without deleting too much information, it can be clever in some cases to replace missing values in numerical features by the mean of this feature.\n",
    "\n",
    "There are not too much outliers in this feature, so replacing missing values by the mean can be a good choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height feature has 75 null values and 425 not null values !\n"
     ]
    }
   ],
   "source": [
    "# Check the proportion of null values in the Height feature\n",
    "height_null_values = sum(dataframe['Height'].isnull() == True)\n",
    "height_notnull_values = sum(dataframe['Height'].isnull() == False)\n",
    "print(\"Height feature has {} null values and {} not null values !\".format(height_null_values, height_notnull_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean value of the Height feature in the dataset, and replace missing values with it\n",
    "height_mean_value = round(dataframe[\"Height\"].mean(), 2)\n",
    "dataframe['Height'].fillna(height_mean_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height feature has 0 null values and 500 not null values !\n"
     ]
    }
   ],
   "source": [
    "# Check the proportion of null values in the Height feature after mean filling\n",
    "height_null_values = sum(dataframe['Height'].isnull() == True)\n",
    "height_notnull_values = sum(dataframe['Height'].isnull() == False)\n",
    "print(\"Height feature has {} null values and {} not null values !\".format(height_null_values, height_notnull_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the `Height` feature missing values have been replaced with the mean value, you shall heterogeneous set of values on this feature to do further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e/ Useless observations deletion\n",
    "\n",
    "The **Name** feature, in my dataset example, serves as an identifier of each observation. We can face cases with real world data, where these identifiers are not filled. There are a bunch of data available, but we cannot link them to a defined indentifier, a specific object or individual.\n",
    "\n",
    "This generally means whathever the analysis you will make on your data, you will be blocked at some point for some cases where you need to identify a data point. Thus, it is sometimes useful to delete these points for some specific analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name feature has 100 null values and 400 not null values !\n"
     ]
    }
   ],
   "source": [
    "# Check the proportion of null values in the Name feature\n",
    "name_null_values = sum(dataframe['Name'].isnull() == True)\n",
    "name_notnull_values = sum(dataframe['Name'].isnull() == False)\n",
    "print(\"Name feature has {} null values and {} not null values !\".format(name_null_values, name_notnull_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete observations where Name feature value is missing\n",
    "dataframe = dataframe.dropna(subset=['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name feature has 0 null values and 400 not null values !\n"
     ]
    }
   ],
   "source": [
    "# Check the proportion of null values in the Name feature after mean filling\n",
    "name_null_values = sum(dataframe['Name'].isnull() == True)\n",
    "name_notnull_values = sum(dataframe['Name'].isnull() == False)\n",
    "print(\"Name feature has {} null values and {} not null values !\".format(name_null_values, name_notnull_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deleting observations that have missing values for the `Name` feature shall reduce your dataset size, but help you to do identification and relationships analysis easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f/ Useless feature deletion\n",
    "\n",
    "There is a **Missing** feature in my dataset that, like its name indicates, misses a large amount of data. When a feature lacks information on the majority of the data points, this means this feature does not really bring something interesting to the analysis done later on.\n",
    "\n",
    "In this case, this feature is considered useless and better be deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Category</th>\n",
       "      <th>Height</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Date</th>\n",
       "      <th>Country</th>\n",
       "      <th>Email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.01</td>\n",
       "      <td>46000</td>\n",
       "      <td>3 1999-23</td>\n",
       "      <td>USA</td>\n",
       "      <td>QgcY2.84ydd@hotmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thomas</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Special</td>\n",
       "      <td>2.10</td>\n",
       "      <td>124000</td>\n",
       "      <td>11 1980-27</td>\n",
       "      <td>USA</td>\n",
       "      <td>2EaDA.nFget@hotmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Patricia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1.55</td>\n",
       "      <td>68000</td>\n",
       "      <td>3 1982-26</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>r2MGQ.0fip0@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Joseph</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Special</td>\n",
       "      <td>1.58</td>\n",
       "      <td>41000</td>\n",
       "      <td>9 2010-13</td>\n",
       "      <td>France</td>\n",
       "      <td>Q8jBw.saull@laposte.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Susan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1.60</td>\n",
       "      <td>38000</td>\n",
       "      <td>11 2000-14</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>yIDdk.YWZMi@gmail.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name  Missing Category  Height  Salary        Date Country  \\\n",
       "2      John      NaN  Unknown    2.01   46000   3 1999-23     USA   \n",
       "4    Thomas     56.0  Special    2.10  124000  11 1980-27     USA   \n",
       "5  Patricia      NaN  Regular    1.55   68000   3 1982-26  Brasil   \n",
       "6    Joseph      NaN  Special    1.58   41000   9 2010-13  France   \n",
       "7     Susan      NaN  Unknown    1.60   38000  11 2000-14  Brasil   \n",
       "\n",
       "                     Email  \n",
       "2  QgcY2.84ydd@hotmail.com  \n",
       "4  2EaDA.nFget@hotmail.com  \n",
       "5    r2MGQ.0fip0@gmail.com  \n",
       "6  Q8jBw.saull@laposte.net  \n",
       "7    yIDdk.YWZMi@gmail.com  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the few first lines of the dataset and especially the Missing feature values\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the \"Missing\" feature of the dataset\n",
    "dataframe = dataframe.drop(['Missing'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Height</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Date</th>\n",
       "      <th>Country</th>\n",
       "      <th>Email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.01</td>\n",
       "      <td>46000</td>\n",
       "      <td>3 1999-23</td>\n",
       "      <td>USA</td>\n",
       "      <td>QgcY2.84ydd@hotmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thomas</td>\n",
       "      <td>Special</td>\n",
       "      <td>2.10</td>\n",
       "      <td>124000</td>\n",
       "      <td>11 1980-27</td>\n",
       "      <td>USA</td>\n",
       "      <td>2EaDA.nFget@hotmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Patricia</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1.55</td>\n",
       "      <td>68000</td>\n",
       "      <td>3 1982-26</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>r2MGQ.0fip0@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Joseph</td>\n",
       "      <td>Special</td>\n",
       "      <td>1.58</td>\n",
       "      <td>41000</td>\n",
       "      <td>9 2010-13</td>\n",
       "      <td>France</td>\n",
       "      <td>Q8jBw.saull@laposte.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Susan</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1.60</td>\n",
       "      <td>38000</td>\n",
       "      <td>11 2000-14</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>yIDdk.YWZMi@gmail.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name Category  Height  Salary        Date Country  \\\n",
       "2      John  Unknown    2.01   46000   3 1999-23     USA   \n",
       "4    Thomas  Special    2.10  124000  11 1980-27     USA   \n",
       "5  Patricia  Regular    1.55   68000   3 1982-26  Brasil   \n",
       "6    Joseph  Special    1.58   41000   9 2010-13  France   \n",
       "7     Susan  Unknown    1.60   38000  11 2000-14  Brasil   \n",
       "\n",
       "                     Email  \n",
       "2  QgcY2.84ydd@hotmail.com  \n",
       "4  2EaDA.nFget@hotmail.com  \n",
       "5    r2MGQ.0fip0@gmail.com  \n",
       "6  Q8jBw.saull@laposte.net  \n",
       "7    yIDdk.YWZMi@gmail.com  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look back at the dataset with Missing feature deleted\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a useless feature is deleted, models and statistics used on the dataset get more precise because they are not perturbated anymore by a lot of incorrected or missing data. It is really important to focus solely on data that has interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### g/ Median filling for erroneous values\n",
    "\n",
    "The **Salary** feature of the dataset has a few values that do not seem plausible, they may be an error. When data is missing or is irrelevant in a numerical feature, and this numerical feature has potentially large outliers in it, replacing the data by the median instead of the mean can be more appropriate.\n",
    "\n",
    "I voluntarily genertated great outliers, and I want to show how we can replace them by the median of the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salary feature : max=497000, min=30000, mean=113130, median=91000\n"
     ]
    }
   ],
   "source": [
    "max_salary = max(dataframe['Salary'])\n",
    "min_salary = min(dataframe['Salary'])\n",
    "mean_salary = math.ceil(round(dataframe['Salary'].mean(), 0))\n",
    "median_salary = math.ceil(dataframe['Salary'].median())\n",
    "print(\"Salary feature : max={}, min={}, mean={}, median={}\".format(max_salary, min_salary, mean_salary, median_salary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean value of the Height feature in the dataset, and replace missing values with it\n",
    "max_salary_no_outlier = mean_salary = math.ceil(round(dataframe['Salary'].mean() * 2.5, 0))\n",
    "dataframe = dataframe.reset_index()\n",
    "high_salary_indices = dataframe[(dataframe[\"Salary\"] > max_salary_no_outlier)].index\n",
    "dataframe.iloc[high_salary_indices, [dataframe.columns.get_loc('Salary')]] = median_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salary feature : max=144000, min=30000, mean=87418, median=91000\n"
     ]
    }
   ],
   "source": [
    "max_salary = max(dataframe[\"Salary\"])\n",
    "min_salary = min(dataframe[\"Salary\"])\n",
    "mean_salary = math.ceil(round(dataframe[\"Salary\"].mean(), 0))\n",
    "median_salary = math.ceil(dataframe[\"Salary\"].median())\n",
    "print(\"Salary feature : max={}, min={}, mean={}, median={}\".format(max_salary, min_salary, mean_salary, median_salary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the `Salary` feature outliers have been replaced with the median value, further analysis shall be more precise and interesting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### h/ Dates wrong formatting\n",
    "\n",
    "There are often dates type features in datasets, in mine we can find the evident **Date** feature. Dates features often present bad formatting according countries, times, or sources where we got your data from. It is vital to clean dates features especially on a uniform form, throughout your feature, and throughout your entire dataset.\n",
    "\n",
    "I invented a confusing representation of dates in my artificially generated dataset, that I need to cleanse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Height</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Date</th>\n",
       "      <th>Country</th>\n",
       "      <th>Email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>John</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.01</td>\n",
       "      <td>46000</td>\n",
       "      <td>3 1999-23</td>\n",
       "      <td>USA</td>\n",
       "      <td>QgcY2.84ydd@hotmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Thomas</td>\n",
       "      <td>Special</td>\n",
       "      <td>2.10</td>\n",
       "      <td>124000</td>\n",
       "      <td>11 1980-27</td>\n",
       "      <td>USA</td>\n",
       "      <td>2EaDA.nFget@hotmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Patricia</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1.55</td>\n",
       "      <td>68000</td>\n",
       "      <td>3 1982-26</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>r2MGQ.0fip0@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>Joseph</td>\n",
       "      <td>Special</td>\n",
       "      <td>1.58</td>\n",
       "      <td>41000</td>\n",
       "      <td>9 2010-13</td>\n",
       "      <td>France</td>\n",
       "      <td>Q8jBw.saull@laposte.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>Susan</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1.60</td>\n",
       "      <td>38000</td>\n",
       "      <td>11 2000-14</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>yIDdk.YWZMi@gmail.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      Name Category  Height  Salary        Date Country  \\\n",
       "0      2      John  Unknown    2.01   46000   3 1999-23     USA   \n",
       "1      4    Thomas  Special    2.10  124000  11 1980-27     USA   \n",
       "2      5  Patricia  Regular    1.55   68000   3 1982-26  Brasil   \n",
       "3      6    Joseph  Special    1.58   41000   9 2010-13  France   \n",
       "4      7     Susan  Unknown    1.60   38000  11 2000-14  Brasil   \n",
       "\n",
       "                     Email  \n",
       "0  QgcY2.84ydd@hotmail.com  \n",
       "1  2EaDA.nFget@hotmail.com  \n",
       "2    r2MGQ.0fip0@gmail.com  \n",
       "3  Q8jBw.saull@laposte.net  \n",
       "4    yIDdk.YWZMi@gmail.com  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first few lines of the dataset, to have a look on the dates format of my Date feature\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the whole feature into a real datetime format, precising the data input format provided\n",
    "dataframe['Date'] = pd.to_datetime(dataframe['Date'], format=\"%m %Y-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Height</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Date</th>\n",
       "      <th>Country</th>\n",
       "      <th>Email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>John</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.01</td>\n",
       "      <td>46000</td>\n",
       "      <td>1999-03-23</td>\n",
       "      <td>USA</td>\n",
       "      <td>QgcY2.84ydd@hotmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Thomas</td>\n",
       "      <td>Special</td>\n",
       "      <td>2.10</td>\n",
       "      <td>124000</td>\n",
       "      <td>1980-11-27</td>\n",
       "      <td>USA</td>\n",
       "      <td>2EaDA.nFget@hotmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Patricia</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1.55</td>\n",
       "      <td>68000</td>\n",
       "      <td>1982-03-26</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>r2MGQ.0fip0@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>Joseph</td>\n",
       "      <td>Special</td>\n",
       "      <td>1.58</td>\n",
       "      <td>41000</td>\n",
       "      <td>2010-09-13</td>\n",
       "      <td>France</td>\n",
       "      <td>Q8jBw.saull@laposte.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>Susan</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1.60</td>\n",
       "      <td>38000</td>\n",
       "      <td>2000-11-14</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>yIDdk.YWZMi@gmail.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      Name Category  Height  Salary       Date Country  \\\n",
       "0      2      John  Unknown    2.01   46000 1999-03-23     USA   \n",
       "1      4    Thomas  Special    2.10  124000 1980-11-27     USA   \n",
       "2      5  Patricia  Regular    1.55   68000 1982-03-26  Brasil   \n",
       "3      6    Joseph  Special    1.58   41000 2010-09-13  France   \n",
       "4      7     Susan  Unknown    1.60   38000 2000-11-14  Brasil   \n",
       "\n",
       "                     Email  \n",
       "0  QgcY2.84ydd@hotmail.com  \n",
       "1  2EaDA.nFget@hotmail.com  \n",
       "2    r2MGQ.0fip0@gmail.com  \n",
       "3  Q8jBw.saull@laposte.net  \n",
       "4    yIDdk.YWZMi@gmail.com  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the good transformation of dates format in the dataset\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now my dates format have been cleansed in the `Date` feature, we should have a better view of dates in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i/ Strange obervations deletion\n",
    "\n",
    "On some features of a dataset, strange values may sometimes appear, and it is difficult to understand whether it is a normal value or a harmful, confusing and non intentional value (that could have been introduced in the process). In the case of my **Email** feature, a very strange or non comprehensive email suffix can mean a lot of things.\n",
    "\n",
    "In this context, I will show how to delete these observations to protect the dataset and run only meaningfull analysis on verified individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gmail.com          162\n",
       "hotmail.com        125\n",
       "laposte.net         82\n",
       "test.xxx            11\n",
       "darkmagic           10\n",
       "weneverknow.com     10\n",
       "Name: Suffices, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check all the existing email suffices in the initial dataset\n",
    "email_suffices = pd.DataFrame({\"Suffices\": dataframe[\"Email\"].str.split(\"@\", expand=True)[1]})\n",
    "email_suffices[\"Suffices\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve indices of observations with harmful email suffices and delete them\n",
    "harmful_email_indices = email_suffices[(email_suffices['Suffices'] == 'darkmagic')\n",
    "                                       | (email_suffices['Suffices'] == 'test.xxx')\n",
    "                                       | (email_suffices['Suffices'] == 'weneverknow.com')].index\n",
    "dataframe.drop(harmful_email_indices, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gmail.com      162\n",
       "hotmail.com    125\n",
       "laposte.net     82\n",
       "Name: Suffices, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check whether the deletion of observations with harmful email suffices worked \n",
    "email_suffices = pd.DataFrame({\"Suffices\": dataframe[\"Email\"].str.split(\"@\", expand=True)[1]})\n",
    "email_suffices[\"Suffices\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the few potentially harmful `Email` addresses have been deleted, we are narrowing our individuals with interesting data and trustable information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
