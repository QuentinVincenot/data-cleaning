{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_generation import *\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = generate_dataset(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Category</th>\n",
       "      <th>Height</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Date</th>\n",
       "      <th>Country</th>\n",
       "      <th>Email</th>\n",
       "      <th>Strange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Special</td>\n",
       "      <td>1.78</td>\n",
       "      <td>72000</td>\n",
       "      <td>3 1951-14</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>T7iP2.FaTN8@hotmail.com</td>\n",
       "      <td>nPM9ie8Dsi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Classic</td>\n",
       "      <td>1.52</td>\n",
       "      <td>138000</td>\n",
       "      <td>1 2003-2</td>\n",
       "      <td>uSa</td>\n",
       "      <td>NAMqv.SNh8u@laposte.net</td>\n",
       "      <td>I1AhNlWRjp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1.61</td>\n",
       "      <td>70000</td>\n",
       "      <td>3 1999-24</td>\n",
       "      <td>Fr</td>\n",
       "      <td>6s6Zs.Ay2FO@weneverknow.com</td>\n",
       "      <td>phPmw5uv8A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Special</td>\n",
       "      <td>1.52</td>\n",
       "      <td>33000</td>\n",
       "      <td>8 1994-10</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>4Rw22.8Dgfv@laposte.net</td>\n",
       "      <td>EuD7n4Ym87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1.74</td>\n",
       "      <td>98000</td>\n",
       "      <td>2 2003-6</td>\n",
       "      <td>USA</td>\n",
       "      <td>ZWU0x.IFOeQ@hotmail.com</td>\n",
       "      <td>KtXAtgdsGK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name  Missing Category  Height  Salary       Date Country  \\\n",
       "0    John      NaN  Special    1.78   72000  3 1951-14  Brasil   \n",
       "1     NaN     64.0  Classic    1.52  138000   1 2003-2     uSa   \n",
       "2  Robert      NaN  Regular    1.61   70000  3 1999-24      Fr   \n",
       "3     NaN      NaN  Special    1.52   33000  8 1994-10  Brasil   \n",
       "4     NaN      NaN  Regular    1.74   98000   2 2003-6     USA   \n",
       "\n",
       "                         Email     Strange  \n",
       "0      T7iP2.FaTN8@hotmail.com  nPM9ie8Dsi  \n",
       "1      NAMqv.SNh8u@laposte.net  I1AhNlWRjp  \n",
       "2  6s6Zs.Ay2FO@weneverknow.com  phPmw5uv8A  \n",
       "3      4Rw22.8Dgfv@laposte.net  EuD7n4Ym87  \n",
       "4      ZWU0x.IFOeQ@hotmail.com  KtXAtgdsGK  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1/ Strange feature deletion\n",
    "\n",
    "Sometimes, there are features in your data that seem relatively strange, and in some cases that are really hard to understand or apprehend. They can be useless features, and to avoid wrong interpretations later in your analysis, deleting this strange feature can be an option.\n",
    "\n",
    "In my dataset, I voluntarily created a **Strange** feature, to showcase the ability to prepare your data and continue your analysis on an appropriate perimeter of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Category</th>\n",
       "      <th>Height</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Date</th>\n",
       "      <th>Country</th>\n",
       "      <th>Email</th>\n",
       "      <th>Strange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Special</td>\n",
       "      <td>1.78</td>\n",
       "      <td>72000</td>\n",
       "      <td>3 1951-14</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>T7iP2.FaTN8@hotmail.com</td>\n",
       "      <td>nPM9ie8Dsi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Classic</td>\n",
       "      <td>1.52</td>\n",
       "      <td>138000</td>\n",
       "      <td>1 2003-2</td>\n",
       "      <td>uSa</td>\n",
       "      <td>NAMqv.SNh8u@laposte.net</td>\n",
       "      <td>I1AhNlWRjp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1.61</td>\n",
       "      <td>70000</td>\n",
       "      <td>3 1999-24</td>\n",
       "      <td>Fr</td>\n",
       "      <td>6s6Zs.Ay2FO@weneverknow.com</td>\n",
       "      <td>phPmw5uv8A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Special</td>\n",
       "      <td>1.52</td>\n",
       "      <td>33000</td>\n",
       "      <td>8 1994-10</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>4Rw22.8Dgfv@laposte.net</td>\n",
       "      <td>EuD7n4Ym87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1.74</td>\n",
       "      <td>98000</td>\n",
       "      <td>2 2003-6</td>\n",
       "      <td>USA</td>\n",
       "      <td>ZWU0x.IFOeQ@hotmail.com</td>\n",
       "      <td>KtXAtgdsGK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name  Missing Category  Height  Salary       Date Country  \\\n",
       "0    John      NaN  Special    1.78   72000  3 1951-14  Brasil   \n",
       "1     NaN     64.0  Classic    1.52  138000   1 2003-2     uSa   \n",
       "2  Robert      NaN  Regular    1.61   70000  3 1999-24      Fr   \n",
       "3     NaN      NaN  Special    1.52   33000  8 1994-10  Brasil   \n",
       "4     NaN      NaN  Regular    1.74   98000   2 2003-6     USA   \n",
       "\n",
       "                         Email     Strange  \n",
       "0      T7iP2.FaTN8@hotmail.com  nPM9ie8Dsi  \n",
       "1      NAMqv.SNh8u@laposte.net  I1AhNlWRjp  \n",
       "2  6s6Zs.Ay2FO@weneverknow.com  phPmw5uv8A  \n",
       "3      4Rw22.8Dgfv@laposte.net  EuD7n4Ym87  \n",
       "4      ZWU0x.IFOeQ@hotmail.com  KtXAtgdsGK  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the first few lines of the dataset to get a sense of data\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the \"Useless\" feature of the dataset\n",
    "dataframe = dataframe.drop(['Strange'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Category</th>\n",
       "      <th>Height</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Date</th>\n",
       "      <th>Country</th>\n",
       "      <th>Email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Special</td>\n",
       "      <td>1.78</td>\n",
       "      <td>72000</td>\n",
       "      <td>3 1951-14</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>T7iP2.FaTN8@hotmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Classic</td>\n",
       "      <td>1.52</td>\n",
       "      <td>138000</td>\n",
       "      <td>1 2003-2</td>\n",
       "      <td>uSa</td>\n",
       "      <td>NAMqv.SNh8u@laposte.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1.61</td>\n",
       "      <td>70000</td>\n",
       "      <td>3 1999-24</td>\n",
       "      <td>Fr</td>\n",
       "      <td>6s6Zs.Ay2FO@weneverknow.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Special</td>\n",
       "      <td>1.52</td>\n",
       "      <td>33000</td>\n",
       "      <td>8 1994-10</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>4Rw22.8Dgfv@laposte.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1.74</td>\n",
       "      <td>98000</td>\n",
       "      <td>2 2003-6</td>\n",
       "      <td>USA</td>\n",
       "      <td>ZWU0x.IFOeQ@hotmail.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name  Missing Category  Height  Salary       Date Country  \\\n",
       "0    John      NaN  Special    1.78   72000  3 1951-14  Brasil   \n",
       "1     NaN     64.0  Classic    1.52  138000   1 2003-2     uSa   \n",
       "2  Robert      NaN  Regular    1.61   70000  3 1999-24      Fr   \n",
       "3     NaN      NaN  Special    1.52   33000  8 1994-10  Brasil   \n",
       "4     NaN      NaN  Regular    1.74   98000   2 2003-6     USA   \n",
       "\n",
       "                         Email  \n",
       "0      T7iP2.FaTN8@hotmail.com  \n",
       "1      NAMqv.SNh8u@laposte.net  \n",
       "2  6s6Zs.Ay2FO@weneverknow.com  \n",
       "3      4Rw22.8Dgfv@laposte.net  \n",
       "4      ZWU0x.IFOeQ@hotmail.com  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have another look on the data without the useless feature that has been deleted\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After deleting the `Strange` feature I was not interested in, I just have a look at my dataset to check the proper deletion of this feature, and continue my Data Cleaning process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2/ Missing values as a special category\n",
    "\n",
    "In this part, I will study the different values that take the **Category** feature of my dataset.\n",
    "\n",
    "I quickly detect there are a few values that are taken and that represent a missing or an invalid value for the category. Therefore, I want to treat all these different values as a single and unique representation of the missing value concept : affect them all to the same category that I can myself rename `Unknown`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Regular    22\n",
       "Classic    10\n",
       "Special     6\n",
       "???         4\n",
       "NaN         3\n",
       "UNKWN       3\n",
       "null        2\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the different values taken by data for the Category feature\n",
    "dataframe['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace data missing values for the Category feature by a single and dedicated value\n",
    "dataframe['Category'].replace(['NaN', 'null', 'UNKWN', '???'], ['Unknown']*4, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Regular    22\n",
       "Unknown    12\n",
       "Classic    10\n",
       "Special     6\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the different values taken by data for the Category feature, after missing category cleaning process\n",
    "dataframe['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having checked my transformed dataset with this single missing value for the Category feature, I will be able to process this feature later on knowing it can take values I had a glance on (`Classic`, `Regular`, `Special`), or the `Unknown` missing value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3/ Fixing spelling mistakes with known correct values\n",
    "\n",
    "There is a **Country** feature in my dataset that contains a few country names, but some of them are sometimes spelled or written in a strange way. That can totally happen in real life when you collect data from multiple sources and these sources do not have the same software/language references.\n",
    "\n",
    "Then, I will try to understand the misspelled values and replace them by a uniformed writting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Brasil          9\n",
       "France          9\n",
       "China           8\n",
       "USA             6\n",
       "Fr              5\n",
       "South Africa    5\n",
       "brUsil          4\n",
       "uSa             3\n",
       "SAF             1\n",
       "Name: Country, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the different values taken by data for the Country feature\n",
    "dataframe['Country'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the different values that can take the Country feature, there are few ones that misspelled or abstracted, but we can guess the name of the real country behind it. For example, *Fr* probably means *France*, *CHinA* and *uSa* is of course a misspelling, *SAF* in an abstraction of *South Africa* and *brUsil* is totally a mistake in data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace misspelled and erroneous values for the Country feature by a known correct values\n",
    "dataframe['Country'].replace(['SAF', 'Fr', 'CHinA', 'uSa', 'brUsil'],\n",
    "                             ['South Africa', 'France', 'China', 'USA', 'Brasil'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "France          14\n",
       "Brasil          13\n",
       "USA              9\n",
       "China            8\n",
       "South Africa     6\n",
       "Name: Country, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the different values taken by data for the Country feature, after fixing misspelled values\n",
    "dataframe['Country'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this spellchecking and fixing step of the Data Cleaning process, we now clearly see the different countries involved in the dataset, with no surprising or confusing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4/ Mean filling for missing values\n",
    "\n",
    "The **Height** feature of the dataset miss a few values, but not a large amount. In order to analyse the data without deleting too much information, it can be clever in some cases to replace missing values in numerical features by the mean of this feature.\n",
    "\n",
    "There are not too much outliers in this feature, so replacing missing values by the mean can be a good choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height feature has 7 null values and 43 not null values !\n"
     ]
    }
   ],
   "source": [
    "# Check the proportion of null values in the Height feature\n",
    "height_null_values = sum(dataframe['Height'].isnull() == True)\n",
    "height_notnull_values = sum(dataframe['Height'].isnull() == False)\n",
    "print(\"Height feature has {} null values and {} not null values !\".format(height_null_values, height_notnull_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean value of the Height feature in the dataset, and replace missing values with it\n",
    "height_mean_value = round(dataframe[\"Height\"].mean(), 2)\n",
    "dataframe['Height'].fillna(height_mean_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height feature has 0 null values and 50 not null values !\n"
     ]
    }
   ],
   "source": [
    "# Check the proportion of null values in the Height feature after mean filling\n",
    "height_null_values = sum(dataframe['Height'].isnull() == True)\n",
    "height_notnull_values = sum(dataframe['Height'].isnull() == False)\n",
    "print(\"Height feature has {} null values and {} not null values !\".format(height_null_values, height_notnull_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the `Height` feature missing values have been replaced with the mean value, you shall heterogeneous set of values on this feature to do further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5/ Useless observations deletion\n",
    "\n",
    "The **Name** feature, in my dataset example, serves as an identifier of each observation. We can face cases with real world data, where these identifiers are not filled. There are a bunch of data available, but we cannot link them to a defined indentifier, a specific object or individual.\n",
    "\n",
    "This generally means whathever the analysis you will make on your data, you will be blocked at some point for some cases where you need to identify a data point. Thus, it is sometimes useful to delete these points for some specific analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name feature has 20 null values and 30 not null values !\n"
     ]
    }
   ],
   "source": [
    "# Check the proportion of null values in the Name feature\n",
    "name_null_values = sum(dataframe['Name'].isnull() == True)\n",
    "name_notnull_values = sum(dataframe['Name'].isnull() == False)\n",
    "print(\"Name feature has {} null values and {} not null values !\".format(name_null_values, name_notnull_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete observations where Name feature value is missing\n",
    "dataframe = dataframe.dropna(subset=['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name feature has 0 null values and 30 not null values !\n"
     ]
    }
   ],
   "source": [
    "# Check the proportion of null values in the Name feature after mean filling\n",
    "name_null_values = sum(dataframe['Name'].isnull() == True)\n",
    "name_notnull_values = sum(dataframe['Name'].isnull() == False)\n",
    "print(\"Name feature has {} null values and {} not null values !\".format(name_null_values, name_notnull_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deleting observations that have missing values for the `Name` feature shall reduce your dataset size, but help you to do identification and relationships analysis easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6/ Useless feature deletion\n",
    "\n",
    "There is a **Missing** feature in my dataset that, like its name indicates, misses a large amount of data. When a feature lacks information on the majority of the data points, this means this feature does not really bring something interesting to the analysis done later on.\n",
    "\n",
    "In this case, this feature is considered useless and better be deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Category</th>\n",
       "      <th>Height</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Date</th>\n",
       "      <th>Country</th>\n",
       "      <th>Email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Special</td>\n",
       "      <td>1.78</td>\n",
       "      <td>72000</td>\n",
       "      <td>3 1951-14</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>T7iP2.FaTN8@hotmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1.61</td>\n",
       "      <td>70000</td>\n",
       "      <td>3 1999-24</td>\n",
       "      <td>France</td>\n",
       "      <td>6s6Zs.Ay2FO@weneverknow.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Margaret</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1.99</td>\n",
       "      <td>51000</td>\n",
       "      <td>9 1989-8</td>\n",
       "      <td>China</td>\n",
       "      <td>ameU8.prboY@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Elizabeth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1.76</td>\n",
       "      <td>128000</td>\n",
       "      <td>3 1997-17</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>7xW6p.pgOzn@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>John</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Special</td>\n",
       "      <td>2.00</td>\n",
       "      <td>46000</td>\n",
       "      <td>10 1975-22</td>\n",
       "      <td>France</td>\n",
       "      <td>eg6H1.YnwFH@darkmagic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name  Missing Category  Height  Salary        Date Country  \\\n",
       "0       John      NaN  Special    1.78   72000   3 1951-14  Brasil   \n",
       "2     Robert      NaN  Regular    1.61   70000   3 1999-24  France   \n",
       "5   Margaret      NaN  Regular    1.99   51000    9 1989-8   China   \n",
       "6  Elizabeth      NaN  Unknown    1.76  128000   3 1997-17  Brasil   \n",
       "7       John      NaN  Special    2.00   46000  10 1975-22  France   \n",
       "\n",
       "                         Email  \n",
       "0      T7iP2.FaTN8@hotmail.com  \n",
       "2  6s6Zs.Ay2FO@weneverknow.com  \n",
       "5        ameU8.prboY@gmail.com  \n",
       "6        7xW6p.pgOzn@gmail.com  \n",
       "7        eg6H1.YnwFH@darkmagic  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the few first lines of the dataset and especially the Missing feature values\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the \"Missing\" feature of the dataset\n",
    "dataframe = dataframe.drop(['Missing'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Height</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Date</th>\n",
       "      <th>Country</th>\n",
       "      <th>Email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>Special</td>\n",
       "      <td>1.78</td>\n",
       "      <td>72000</td>\n",
       "      <td>3 1951-14</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>T7iP2.FaTN8@hotmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robert</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1.61</td>\n",
       "      <td>70000</td>\n",
       "      <td>3 1999-24</td>\n",
       "      <td>France</td>\n",
       "      <td>6s6Zs.Ay2FO@weneverknow.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Margaret</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1.99</td>\n",
       "      <td>51000</td>\n",
       "      <td>9 1989-8</td>\n",
       "      <td>China</td>\n",
       "      <td>ameU8.prboY@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Elizabeth</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1.76</td>\n",
       "      <td>128000</td>\n",
       "      <td>3 1997-17</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>7xW6p.pgOzn@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>John</td>\n",
       "      <td>Special</td>\n",
       "      <td>2.00</td>\n",
       "      <td>46000</td>\n",
       "      <td>10 1975-22</td>\n",
       "      <td>France</td>\n",
       "      <td>eg6H1.YnwFH@darkmagic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name Category  Height  Salary        Date Country  \\\n",
       "0       John  Special    1.78   72000   3 1951-14  Brasil   \n",
       "2     Robert  Regular    1.61   70000   3 1999-24  France   \n",
       "5   Margaret  Regular    1.99   51000    9 1989-8   China   \n",
       "6  Elizabeth  Unknown    1.76  128000   3 1997-17  Brasil   \n",
       "7       John  Special    2.00   46000  10 1975-22  France   \n",
       "\n",
       "                         Email  \n",
       "0      T7iP2.FaTN8@hotmail.com  \n",
       "2  6s6Zs.Ay2FO@weneverknow.com  \n",
       "5        ameU8.prboY@gmail.com  \n",
       "6        7xW6p.pgOzn@gmail.com  \n",
       "7        eg6H1.YnwFH@darkmagic  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look back at the dataset with Missing feature deleted\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a useless feature is deleted, models and statistics used on the dataset get more precise because they are not perturbated anymore by a lot of incorrected or missing data. It is really important to focus solely on data that has interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7/ Median filling for erroneous values\n",
    "\n",
    "The **Salary** feature of the dataset has a few values that do not seem plausible, they may be an error. When data is missing or is irrelevant in a numerical feature, and this numerical feature has potentially large outliers in it, replacing the data by the median instead of the mean can be more appropriate.\n",
    "\n",
    "I voluntarily genertated great outliers, and I want to show how we can replace them by the median of the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salary feature : max=463000, min=34000, mean=93367, median=88500\n"
     ]
    }
   ],
   "source": [
    "max_salary = max(dataframe['Salary'])\n",
    "min_salary = min(dataframe['Salary'])\n",
    "mean_salary = math.ceil(round(dataframe['Salary'].mean(), 0))\n",
    "median_salary = math.ceil(dataframe['Salary'].median())\n",
    "print(\"Salary feature : max={}, min={}, mean={}, median={}\".format(max_salary, min_salary, mean_salary, median_salary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean value of the Height feature in the dataset, and replace missing values with it\n",
    "max_salary_no_outlier = mean_salary = math.ceil(round(dataframe['Salary'].mean() * 2.5, 0))\n",
    "dataframe = dataframe.reset_index()\n",
    "high_salary_indices = dataframe[(dataframe[\"Salary\"] > max_salary_no_outlier)].index\n",
    "dataframe.iloc[high_salary_indices, [dataframe.columns.get_loc('Salary')]] = median_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salary feature : max=137000, min=34000, mean=80883, median=88250\n"
     ]
    }
   ],
   "source": [
    "max_salary = max(dataframe[\"Salary\"])\n",
    "min_salary = min(dataframe[\"Salary\"])\n",
    "mean_salary = math.ceil(round(dataframe[\"Salary\"].mean(), 0))\n",
    "median_salary = math.ceil(dataframe[\"Salary\"].median())\n",
    "print(\"Salary feature : max={}, min={}, mean={}, median={}\".format(max_salary, min_salary, mean_salary, median_salary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the `Salary` feature outliers have been replaced with the median value, further analysis shall be more precise and interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
