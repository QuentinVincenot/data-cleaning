{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "This notebook aims to show a subset of methods used to clean datasets before performing further analysis and visualisations.\n",
    "\n",
    "It is splitted in 2 parts : the dataset generation, and the data cleaning process.  \n",
    "- **Dataset generation** permits to parametrise the dataset generation.\n",
    "- **Data cleaning process** showcases the different methods explained in the README."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Dataset generation\n",
    "\n",
    "This section of the notebook permits to randomly generate a dataset composed of 9 columns and a parametered number of rows. Errors are also generated randomly with a possibly changeable rate for each kind of errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Category</th>\n",
       "      <th>Height</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Date</th>\n",
       "      <th>Country</th>\n",
       "      <th>Email</th>\n",
       "      <th>Strange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Patricia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.82</td>\n",
       "      <td>129000</td>\n",
       "      <td>10 1965-11</td>\n",
       "      <td>USA</td>\n",
       "      <td>iYpKe.6ZiHz@hotmail.com</td>\n",
       "      <td>CTgtZepjbt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Charles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNKWN</td>\n",
       "      <td>1.83</td>\n",
       "      <td>101000</td>\n",
       "      <td>10 2018-2</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>hcwFo.AYXPZ@hotmail.com</td>\n",
       "      <td>6xhQEgD7Hx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1.53</td>\n",
       "      <td>135000</td>\n",
       "      <td>8 1958-23</td>\n",
       "      <td>USA</td>\n",
       "      <td>uRqE7.OuEBB@gmail.com</td>\n",
       "      <td>dD7JqCAs0r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sarah</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Regular</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79000</td>\n",
       "      <td>3 1965-2</td>\n",
       "      <td>SAF</td>\n",
       "      <td>oZUD1.7kRFB@hotmail.com</td>\n",
       "      <td>L44NjTer2b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Susan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>470000</td>\n",
       "      <td>2 2003-5</td>\n",
       "      <td>Fr</td>\n",
       "      <td>WtpzK.zgugM@test.xxx</td>\n",
       "      <td>gjV8vO9hM5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Linda</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Special</td>\n",
       "      <td>2.04</td>\n",
       "      <td>141000</td>\n",
       "      <td>11 1959-7</td>\n",
       "      <td>USA</td>\n",
       "      <td>8yFow.tGlcK@gmail.com</td>\n",
       "      <td>d9LUKQgfoZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jessica</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.91</td>\n",
       "      <td>137000</td>\n",
       "      <td>3 1966-14</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>KBKKW.m4AcI@gmail.com</td>\n",
       "      <td>qj7syQFVW1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>William</td>\n",
       "      <td>4.0</td>\n",
       "      <td>UNKWN</td>\n",
       "      <td>1.82</td>\n",
       "      <td>46000</td>\n",
       "      <td>8 1975-26</td>\n",
       "      <td>China</td>\n",
       "      <td>niKP9.PDcNX@gmail.com</td>\n",
       "      <td>Wu2wGuY3lZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jennifer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Special</td>\n",
       "      <td>1.86</td>\n",
       "      <td>107000</td>\n",
       "      <td>9 1990-26</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>nZwdL.VB4Rv@weneverknow.com</td>\n",
       "      <td>hcWPTp7DCx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Joseph</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Regular</td>\n",
       "      <td>2.02</td>\n",
       "      <td>116000</td>\n",
       "      <td>5 1974-15</td>\n",
       "      <td>CHinA</td>\n",
       "      <td>AOOmV.7nToS@hotmail.com</td>\n",
       "      <td>X8y5DplRvl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name  Missing Category  Height  Salary        Date       Country  \\\n",
       "0  Patricia      NaN      NaN    1.82  129000  10 1965-11           USA   \n",
       "1   Charles      NaN    UNKWN    1.83  101000   10 2018-2  South Africa   \n",
       "2       NaN      NaN  Regular    1.53  135000   8 1958-23           USA   \n",
       "3     Sarah      NaN  Regular     NaN   79000    3 1965-2           SAF   \n",
       "4     Susan      NaN      NaN     NaN  470000    2 2003-5            Fr   \n",
       "5     Linda      NaN  Special    2.04  141000   11 1959-7           USA   \n",
       "6   Jessica      NaN      NaN    1.91  137000   3 1966-14        Brasil   \n",
       "7   William      4.0    UNKWN    1.82   46000   8 1975-26         China   \n",
       "8  Jennifer      NaN  Special    1.86  107000   9 1990-26        Brasil   \n",
       "9    Joseph      NaN  Regular    2.02  116000   5 1974-15         CHinA   \n",
       "\n",
       "                         Email     Strange  \n",
       "0      iYpKe.6ZiHz@hotmail.com  CTgtZepjbt  \n",
       "1      hcwFo.AYXPZ@hotmail.com  6xhQEgD7Hx  \n",
       "2        uRqE7.OuEBB@gmail.com  dD7JqCAs0r  \n",
       "3      oZUD1.7kRFB@hotmail.com  L44NjTer2b  \n",
       "4         WtpzK.zgugM@test.xxx  gjV8vO9hM5  \n",
       "5        8yFow.tGlcK@gmail.com  d9LUKQgfoZ  \n",
       "6        KBKKW.m4AcI@gmail.com  qj7syQFVW1  \n",
       "7        niKP9.PDcNX@gmail.com  Wu2wGuY3lZ  \n",
       "8  nZwdL.VB4Rv@weneverknow.com  hcWPTp7DCx  \n",
       "9      AOOmV.7nToS@hotmail.com  X8y5DplRvl  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataset_generation import *\n",
    "dataframe = generate_dataset(length=500, name_errors=0.2, missing_errors=0.8, category_errors=0.25,\n",
    "                             height_errors=0.15, salary_errors=0.07)\n",
    "dataframe.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Data Cleaning pipeline\n",
    "\n",
    "### a/ Strange feature deletion\n",
    "\n",
    "Sometimes, there are features in your data that seem relatively strange, and in some cases that are really hard to understand or apprehend. They can be useless features, and to avoid wrong interpretations later in your analysis, deleting this strange feature can be an option.\n",
    "\n",
    "In my dataset, I voluntarily created a **Strange** feature, to showcase the ability to prepare your data and continue your analysis on an appropriate perimeter of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Category</th>\n",
       "      <th>Height</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Date</th>\n",
       "      <th>Country</th>\n",
       "      <th>Email</th>\n",
       "      <th>Strange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Patricia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.82</td>\n",
       "      <td>129000</td>\n",
       "      <td>10 1965-11</td>\n",
       "      <td>USA</td>\n",
       "      <td>iYpKe.6ZiHz@hotmail.com</td>\n",
       "      <td>CTgtZepjbt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Charles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNKWN</td>\n",
       "      <td>1.83</td>\n",
       "      <td>101000</td>\n",
       "      <td>10 2018-2</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>hcwFo.AYXPZ@hotmail.com</td>\n",
       "      <td>6xhQEgD7Hx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1.53</td>\n",
       "      <td>135000</td>\n",
       "      <td>8 1958-23</td>\n",
       "      <td>USA</td>\n",
       "      <td>uRqE7.OuEBB@gmail.com</td>\n",
       "      <td>dD7JqCAs0r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sarah</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Regular</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79000</td>\n",
       "      <td>3 1965-2</td>\n",
       "      <td>SAF</td>\n",
       "      <td>oZUD1.7kRFB@hotmail.com</td>\n",
       "      <td>L44NjTer2b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Susan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>470000</td>\n",
       "      <td>2 2003-5</td>\n",
       "      <td>Fr</td>\n",
       "      <td>WtpzK.zgugM@test.xxx</td>\n",
       "      <td>gjV8vO9hM5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name  Missing Category  Height  Salary        Date       Country  \\\n",
       "0  Patricia      NaN      NaN    1.82  129000  10 1965-11           USA   \n",
       "1   Charles      NaN    UNKWN    1.83  101000   10 2018-2  South Africa   \n",
       "2       NaN      NaN  Regular    1.53  135000   8 1958-23           USA   \n",
       "3     Sarah      NaN  Regular     NaN   79000    3 1965-2           SAF   \n",
       "4     Susan      NaN      NaN     NaN  470000    2 2003-5            Fr   \n",
       "\n",
       "                     Email     Strange  \n",
       "0  iYpKe.6ZiHz@hotmail.com  CTgtZepjbt  \n",
       "1  hcwFo.AYXPZ@hotmail.com  6xhQEgD7Hx  \n",
       "2    uRqE7.OuEBB@gmail.com  dD7JqCAs0r  \n",
       "3  oZUD1.7kRFB@hotmail.com  L44NjTer2b  \n",
       "4     WtpzK.zgugM@test.xxx  gjV8vO9hM5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the first few lines of the dataset to get a sense of data\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the \"Useless\" feature of the dataset\n",
    "dataframe = dataframe.drop(['Strange'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Category</th>\n",
       "      <th>Height</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Date</th>\n",
       "      <th>Country</th>\n",
       "      <th>Email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Patricia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.82</td>\n",
       "      <td>129000</td>\n",
       "      <td>10 1965-11</td>\n",
       "      <td>USA</td>\n",
       "      <td>iYpKe.6ZiHz@hotmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Charles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNKWN</td>\n",
       "      <td>1.83</td>\n",
       "      <td>101000</td>\n",
       "      <td>10 2018-2</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>hcwFo.AYXPZ@hotmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1.53</td>\n",
       "      <td>135000</td>\n",
       "      <td>8 1958-23</td>\n",
       "      <td>USA</td>\n",
       "      <td>uRqE7.OuEBB@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sarah</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Regular</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79000</td>\n",
       "      <td>3 1965-2</td>\n",
       "      <td>SAF</td>\n",
       "      <td>oZUD1.7kRFB@hotmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Susan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>470000</td>\n",
       "      <td>2 2003-5</td>\n",
       "      <td>Fr</td>\n",
       "      <td>WtpzK.zgugM@test.xxx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name  Missing Category  Height  Salary        Date       Country  \\\n",
       "0  Patricia      NaN      NaN    1.82  129000  10 1965-11           USA   \n",
       "1   Charles      NaN    UNKWN    1.83  101000   10 2018-2  South Africa   \n",
       "2       NaN      NaN  Regular    1.53  135000   8 1958-23           USA   \n",
       "3     Sarah      NaN  Regular     NaN   79000    3 1965-2           SAF   \n",
       "4     Susan      NaN      NaN     NaN  470000    2 2003-5            Fr   \n",
       "\n",
       "                     Email  \n",
       "0  iYpKe.6ZiHz@hotmail.com  \n",
       "1  hcwFo.AYXPZ@hotmail.com  \n",
       "2    uRqE7.OuEBB@gmail.com  \n",
       "3  oZUD1.7kRFB@hotmail.com  \n",
       "4     WtpzK.zgugM@test.xxx  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have another look on the data without the useless feature that has been deleted\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After deleting the `Strange` feature I was not interested in, I just have a look at my dataset to check the proper deletion of this feature, and continue my Data Cleaning process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b/ Missing values as a special category\n",
    "\n",
    "In this part, I will study the different values that take the **Category** feature of my dataset.\n",
    "\n",
    "I quickly detect there are a few values that are taken and that represent a missing or an invalid value for the category. Therefore, I want to treat all these different values as a single and unique representation of the missing value concept : affect them all to the same category that I can myself rename `Unknown`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Special    136\n",
       "Regular    133\n",
       "Classic    106\n",
       "NaN         40\n",
       "???         30\n",
       "null        29\n",
       "UNKWN       26\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the different values taken by data for the Category feature\n",
    "dataframe['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace data missing values for the Category feature by a single and dedicated value\n",
    "dataframe['Category'].replace(['NaN', 'null', 'UNKWN', '???'], ['Unknown']*4, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Special    136\n",
       "Regular    133\n",
       "Unknown    125\n",
       "Classic    106\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the different values taken by data for the Category feature, after missing category cleaning process\n",
    "dataframe['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having checked my transformed dataset with this single missing value for the Category feature, I will be able to process this feature later on knowing it can take values I had a glance on (`Classic`, `Regular`, `Special`), or the `Unknown` missing value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c/ Fixing spelling mistakes with known correct values\n",
    "\n",
    "There is a **Country** feature in my dataset that contains a few country names, but some of them are sometimes spelled or written in a strange way. That can totally happen in real life when you collect data from multiple sources and these sources do not have the same software/language references.\n",
    "\n",
    "Then, I will try to understand the misspelled values and replace them by a uniformed writting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Brasil          83\n",
       "USA             76\n",
       "France          75\n",
       "China           74\n",
       "South Africa    74\n",
       "Fr              30\n",
       "SAF             24\n",
       "brUsil          24\n",
       "uSa             23\n",
       "CHinA           17\n",
       "Name: Country, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the different values taken by data for the Country feature\n",
    "dataframe['Country'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the different values that can take the Country feature, there are few ones that misspelled or abstracted, but we can guess the name of the real country behind it. For example, *Fr* probably means *France*, *CHinA* and *uSa* is of course a misspelling, *SAF* in an abstraction of *South Africa* and *brUsil* is totally a mistake in data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace misspelled and erroneous values for the Country feature by a known correct values\n",
    "dataframe['Country'].replace(['SAF', 'Fr', 'CHinA', 'uSa', 'brUsil'],\n",
    "                             ['South Africa', 'France', 'China', 'USA', 'Brasil'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Brasil          107\n",
       "France          105\n",
       "USA              99\n",
       "South Africa     98\n",
       "China            91\n",
       "Name: Country, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the different values taken by data for the Country feature, after fixing misspelled values\n",
    "dataframe['Country'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this spellchecking and fixing step of the Data Cleaning process, we now clearly see the different countries involved in the dataset, with no surprising or confusing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d/ Mean filling for missing values\n",
    "\n",
    "The **Height** feature of the dataset miss a few values, but not a large amount. In order to analyse the data without deleting too much information, it can be clever in some cases to replace missing values in numerical features by the mean of this feature.\n",
    "\n",
    "There are not too much outliers in this feature, so replacing missing values by the mean can be a good choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height feature has 75 null values and 425 not null values !\n"
     ]
    }
   ],
   "source": [
    "# Check the proportion of null values in the Height feature\n",
    "height_null_values = sum(dataframe['Height'].isnull() == True)\n",
    "height_notnull_values = sum(dataframe['Height'].isnull() == False)\n",
    "print(\"Height feature has {} null values and {} not null values !\".format(height_null_values, height_notnull_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean value of the Height feature in the dataset, and replace missing values with it\n",
    "height_mean_value = round(dataframe[\"Height\"].mean(), 2)\n",
    "dataframe['Height'].fillna(height_mean_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height feature has 0 null values and 500 not null values !\n"
     ]
    }
   ],
   "source": [
    "# Check the proportion of null values in the Height feature after mean filling\n",
    "height_null_values = sum(dataframe['Height'].isnull() == True)\n",
    "height_notnull_values = sum(dataframe['Height'].isnull() == False)\n",
    "print(\"Height feature has {} null values and {} not null values !\".format(height_null_values, height_notnull_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the `Height` feature missing values have been replaced with the mean value, you shall heterogeneous set of values on this feature to do further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e/ Useless observations deletion\n",
    "\n",
    "The **Name** feature, in my dataset example, serves as an identifier of each observation. We can face cases with real world data, where these identifiers are not filled. There are a bunch of data available, but we cannot link them to a defined indentifier, a specific object or individual.\n",
    "\n",
    "This generally means whathever the analysis you will make on your data, you will be blocked at some point for some cases where you need to identify a data point. Thus, it is sometimes useful to delete these points for some specific analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name feature has 100 null values and 400 not null values !\n"
     ]
    }
   ],
   "source": [
    "# Check the proportion of null values in the Name feature\n",
    "name_null_values = sum(dataframe['Name'].isnull() == True)\n",
    "name_notnull_values = sum(dataframe['Name'].isnull() == False)\n",
    "print(\"Name feature has {} null values and {} not null values !\".format(name_null_values, name_notnull_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete observations where Name feature value is missing\n",
    "dataframe = dataframe.dropna(subset=['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name feature has 0 null values and 400 not null values !\n"
     ]
    }
   ],
   "source": [
    "# Check the proportion of null values in the Name feature after mean filling\n",
    "name_null_values = sum(dataframe['Name'].isnull() == True)\n",
    "name_notnull_values = sum(dataframe['Name'].isnull() == False)\n",
    "print(\"Name feature has {} null values and {} not null values !\".format(name_null_values, name_notnull_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deleting observations that have missing values for the `Name` feature shall reduce your dataset size, but help you to do identification and relationships analysis easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f/ Useless feature deletion\n",
    "\n",
    "There is a **Missing** feature in my dataset that, like its name indicates, misses a large amount of data. When a feature lacks information on the majority of the data points, this means this feature does not really bring something interesting to the analysis done later on.\n",
    "\n",
    "In this case, this feature is considered useless and better be deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Category</th>\n",
       "      <th>Height</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Date</th>\n",
       "      <th>Country</th>\n",
       "      <th>Email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Patricia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1.82</td>\n",
       "      <td>129000</td>\n",
       "      <td>10 1965-11</td>\n",
       "      <td>USA</td>\n",
       "      <td>iYpKe.6ZiHz@hotmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Charles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1.83</td>\n",
       "      <td>101000</td>\n",
       "      <td>10 2018-2</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>hcwFo.AYXPZ@hotmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sarah</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1.79</td>\n",
       "      <td>79000</td>\n",
       "      <td>3 1965-2</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>oZUD1.7kRFB@hotmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Susan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1.79</td>\n",
       "      <td>470000</td>\n",
       "      <td>2 2003-5</td>\n",
       "      <td>France</td>\n",
       "      <td>WtpzK.zgugM@test.xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Linda</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Special</td>\n",
       "      <td>2.04</td>\n",
       "      <td>141000</td>\n",
       "      <td>11 1959-7</td>\n",
       "      <td>USA</td>\n",
       "      <td>8yFow.tGlcK@gmail.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name  Missing Category  Height  Salary        Date       Country  \\\n",
       "0  Patricia      NaN  Unknown    1.82  129000  10 1965-11           USA   \n",
       "1   Charles      NaN  Unknown    1.83  101000   10 2018-2  South Africa   \n",
       "3     Sarah      NaN  Regular    1.79   79000    3 1965-2  South Africa   \n",
       "4     Susan      NaN  Unknown    1.79  470000    2 2003-5        France   \n",
       "5     Linda      NaN  Special    2.04  141000   11 1959-7           USA   \n",
       "\n",
       "                     Email  \n",
       "0  iYpKe.6ZiHz@hotmail.com  \n",
       "1  hcwFo.AYXPZ@hotmail.com  \n",
       "3  oZUD1.7kRFB@hotmail.com  \n",
       "4     WtpzK.zgugM@test.xxx  \n",
       "5    8yFow.tGlcK@gmail.com  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the few first lines of the dataset and especially the Missing feature values\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the \"Missing\" feature of the dataset\n",
    "dataframe = dataframe.drop(['Missing'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Height</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Date</th>\n",
       "      <th>Country</th>\n",
       "      <th>Email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Patricia</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1.82</td>\n",
       "      <td>129000</td>\n",
       "      <td>10 1965-11</td>\n",
       "      <td>USA</td>\n",
       "      <td>iYpKe.6ZiHz@hotmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Charles</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1.83</td>\n",
       "      <td>101000</td>\n",
       "      <td>10 2018-2</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>hcwFo.AYXPZ@hotmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sarah</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1.79</td>\n",
       "      <td>79000</td>\n",
       "      <td>3 1965-2</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>oZUD1.7kRFB@hotmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Susan</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1.79</td>\n",
       "      <td>470000</td>\n",
       "      <td>2 2003-5</td>\n",
       "      <td>France</td>\n",
       "      <td>WtpzK.zgugM@test.xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Linda</td>\n",
       "      <td>Special</td>\n",
       "      <td>2.04</td>\n",
       "      <td>141000</td>\n",
       "      <td>11 1959-7</td>\n",
       "      <td>USA</td>\n",
       "      <td>8yFow.tGlcK@gmail.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name Category  Height  Salary        Date       Country  \\\n",
       "0  Patricia  Unknown    1.82  129000  10 1965-11           USA   \n",
       "1   Charles  Unknown    1.83  101000   10 2018-2  South Africa   \n",
       "3     Sarah  Regular    1.79   79000    3 1965-2  South Africa   \n",
       "4     Susan  Unknown    1.79  470000    2 2003-5        France   \n",
       "5     Linda  Special    2.04  141000   11 1959-7           USA   \n",
       "\n",
       "                     Email  \n",
       "0  iYpKe.6ZiHz@hotmail.com  \n",
       "1  hcwFo.AYXPZ@hotmail.com  \n",
       "3  oZUD1.7kRFB@hotmail.com  \n",
       "4     WtpzK.zgugM@test.xxx  \n",
       "5    8yFow.tGlcK@gmail.com  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look back at the dataset with Missing feature deleted\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a useless feature is deleted, models and statistics used on the dataset get more precise because they are not perturbated anymore by a lot of incorrected or missing data. It is really important to focus solely on data that has interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### g/ Median filling for erroneous values\n",
    "\n",
    "The **Salary** feature of the dataset has a few values that do not seem plausible, they may be an error. When data is missing or is irrelevant in a numerical feature, and this numerical feature has potentially large outliers in it, replacing the data by the median instead of the mean can be more appropriate.\n",
    "\n",
    "I voluntarily genertated great outliers, and I want to show how we can replace them by the median of the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salary feature : max=499000, min=30000, mean=115658, median=94000\n"
     ]
    }
   ],
   "source": [
    "max_salary = max(dataframe['Salary'])\n",
    "min_salary = min(dataframe['Salary'])\n",
    "mean_salary = math.ceil(round(dataframe['Salary'].mean(), 0))\n",
    "median_salary = math.ceil(dataframe['Salary'].median())\n",
    "print(\"Salary feature : max={}, min={}, mean={}, median={}\".format(max_salary, min_salary, mean_salary, median_salary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean value of the Height feature in the dataset, and replace missing values with it\n",
    "max_salary_no_outlier = mean_salary = math.ceil(round(dataframe['Salary'].mean() * 2.5, 0))\n",
    "dataframe = dataframe.reset_index(drop=True)\n",
    "high_salary_indices = dataframe[(dataframe[\"Salary\"] > max_salary_no_outlier)].index\n",
    "dataframe.iloc[high_salary_indices, [dataframe.columns.get_loc('Salary')]] = median_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salary feature : max=144000, min=30000, mean=89862, median=94000\n"
     ]
    }
   ],
   "source": [
    "max_salary = max(dataframe[\"Salary\"])\n",
    "min_salary = min(dataframe[\"Salary\"])\n",
    "mean_salary = math.ceil(round(dataframe[\"Salary\"].mean(), 0))\n",
    "median_salary = math.ceil(dataframe[\"Salary\"].median())\n",
    "print(\"Salary feature : max={}, min={}, mean={}, median={}\".format(max_salary, min_salary, mean_salary, median_salary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the `Salary` feature outliers have been replaced with the median value, further analysis shall be more precise and interesting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### h/ Dates wrong formatting\n",
    "\n",
    "There are often dates type features in datasets, in mine we can find the evident **Date** feature. Dates features often present bad formatting according countries, times, or sources where we got your data from. It is vital to clean dates features especially on a uniform form, throughout your feature, and throughout your entire dataset.\n",
    "\n",
    "I invented a confusing representation of dates in my artificially generated dataset, that I need to cleanse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Height</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Date</th>\n",
       "      <th>Country</th>\n",
       "      <th>Email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Patricia</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1.82</td>\n",
       "      <td>129000</td>\n",
       "      <td>10 1965-11</td>\n",
       "      <td>USA</td>\n",
       "      <td>iYpKe.6ZiHz@hotmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Charles</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1.83</td>\n",
       "      <td>101000</td>\n",
       "      <td>10 2018-2</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>hcwFo.AYXPZ@hotmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sarah</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1.79</td>\n",
       "      <td>79000</td>\n",
       "      <td>3 1965-2</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>oZUD1.7kRFB@hotmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Susan</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1.79</td>\n",
       "      <td>94000</td>\n",
       "      <td>2 2003-5</td>\n",
       "      <td>France</td>\n",
       "      <td>WtpzK.zgugM@test.xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linda</td>\n",
       "      <td>Special</td>\n",
       "      <td>2.04</td>\n",
       "      <td>141000</td>\n",
       "      <td>11 1959-7</td>\n",
       "      <td>USA</td>\n",
       "      <td>8yFow.tGlcK@gmail.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name Category  Height  Salary        Date       Country  \\\n",
       "0  Patricia  Unknown    1.82  129000  10 1965-11           USA   \n",
       "1   Charles  Unknown    1.83  101000   10 2018-2  South Africa   \n",
       "2     Sarah  Regular    1.79   79000    3 1965-2  South Africa   \n",
       "3     Susan  Unknown    1.79   94000    2 2003-5        France   \n",
       "4     Linda  Special    2.04  141000   11 1959-7           USA   \n",
       "\n",
       "                     Email  \n",
       "0  iYpKe.6ZiHz@hotmail.com  \n",
       "1  hcwFo.AYXPZ@hotmail.com  \n",
       "2  oZUD1.7kRFB@hotmail.com  \n",
       "3     WtpzK.zgugM@test.xxx  \n",
       "4    8yFow.tGlcK@gmail.com  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first few lines of the dataset, to have a look on the dates format of my Date feature\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the whole feature into a real datetime format, precising the data input format provided\n",
    "dataframe['Date'] = pd.to_datetime(dataframe['Date'], format=\"%m %Y-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Height</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Date</th>\n",
       "      <th>Country</th>\n",
       "      <th>Email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Patricia</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1.82</td>\n",
       "      <td>129000</td>\n",
       "      <td>1965-10-11</td>\n",
       "      <td>USA</td>\n",
       "      <td>iYpKe.6ZiHz@hotmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Charles</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1.83</td>\n",
       "      <td>101000</td>\n",
       "      <td>2018-10-02</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>hcwFo.AYXPZ@hotmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sarah</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1.79</td>\n",
       "      <td>79000</td>\n",
       "      <td>1965-03-02</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>oZUD1.7kRFB@hotmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Susan</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1.79</td>\n",
       "      <td>94000</td>\n",
       "      <td>2003-02-05</td>\n",
       "      <td>France</td>\n",
       "      <td>WtpzK.zgugM@test.xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linda</td>\n",
       "      <td>Special</td>\n",
       "      <td>2.04</td>\n",
       "      <td>141000</td>\n",
       "      <td>1959-11-07</td>\n",
       "      <td>USA</td>\n",
       "      <td>8yFow.tGlcK@gmail.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name Category  Height  Salary       Date       Country  \\\n",
       "0  Patricia  Unknown    1.82  129000 1965-10-11           USA   \n",
       "1   Charles  Unknown    1.83  101000 2018-10-02  South Africa   \n",
       "2     Sarah  Regular    1.79   79000 1965-03-02  South Africa   \n",
       "3     Susan  Unknown    1.79   94000 2003-02-05        France   \n",
       "4     Linda  Special    2.04  141000 1959-11-07           USA   \n",
       "\n",
       "                     Email  \n",
       "0  iYpKe.6ZiHz@hotmail.com  \n",
       "1  hcwFo.AYXPZ@hotmail.com  \n",
       "2  oZUD1.7kRFB@hotmail.com  \n",
       "3     WtpzK.zgugM@test.xxx  \n",
       "4    8yFow.tGlcK@gmail.com  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the good transformation of dates format in the dataset\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now my dates format have been cleansed in the `Date` feature, we should have a better view of dates in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i/ Strange obervations deletion\n",
    "\n",
    "On some features of a dataset, strange values may sometimes appear, and it is difficult to understand whether it is a normal value or a harmful, confusing and non intentional value (that could have been introduced in the process). In the case of my **Email** feature, a very strange or non comprehensive email suffix can mean a lot of things.\n",
    "\n",
    "In this context, I will show how to delete these observations to protect the dataset and run only meaningfull analysis on verified individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gmail.com          171\n",
       "hotmail.com        110\n",
       "laposte.net         80\n",
       "test.xxx            15\n",
       "weneverknow.com     14\n",
       "darkmagic           10\n",
       "Name: Suffices, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check all the existing email suffices in the initial dataset\n",
    "email_suffices = pd.DataFrame({\"Suffices\": dataframe[\"Email\"].str.split(\"@\", expand=True)[1]})\n",
    "email_suffices[\"Suffices\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve indices of observations with harmful email suffices and delete them\n",
    "harmful_email_indices = email_suffices[(email_suffices['Suffices'] == 'darkmagic')\n",
    "                                       | (email_suffices['Suffices'] == 'test.xxx')\n",
    "                                       | (email_suffices['Suffices'] == 'weneverknow.com')].index\n",
    "dataframe.drop(harmful_email_indices, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gmail.com      171\n",
       "hotmail.com    110\n",
       "laposte.net     80\n",
       "Name: Suffices, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check whether the deletion of observations with harmful email suffices worked \n",
    "email_suffices = pd.DataFrame({\"Suffices\": dataframe[\"Email\"].str.split(\"@\", expand=True)[1]})\n",
    "email_suffices[\"Suffices\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the few potentially harmful `Email` addresses have been deleted, we are narrowing our individuals with interesting data and trustable information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Conclusion\n",
    "\n",
    "This section of the notebook shows the results of my Data Cleaning pipeline applied to my previously generated dataset. There are of course less columns and rows, but data is clean, readable, and ready to be further analysed with other Data Science techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Height</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Date</th>\n",
       "      <th>Country</th>\n",
       "      <th>Email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Patricia</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1.82</td>\n",
       "      <td>129000</td>\n",
       "      <td>1965-10-11</td>\n",
       "      <td>USA</td>\n",
       "      <td>iYpKe.6ZiHz@hotmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Charles</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1.83</td>\n",
       "      <td>101000</td>\n",
       "      <td>2018-10-02</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>hcwFo.AYXPZ@hotmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sarah</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1.79</td>\n",
       "      <td>79000</td>\n",
       "      <td>1965-03-02</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>oZUD1.7kRFB@hotmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linda</td>\n",
       "      <td>Special</td>\n",
       "      <td>2.04</td>\n",
       "      <td>141000</td>\n",
       "      <td>1959-11-07</td>\n",
       "      <td>USA</td>\n",
       "      <td>8yFow.tGlcK@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jessica</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1.91</td>\n",
       "      <td>137000</td>\n",
       "      <td>1966-03-14</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>KBKKW.m4AcI@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>William</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1.82</td>\n",
       "      <td>46000</td>\n",
       "      <td>1975-08-26</td>\n",
       "      <td>China</td>\n",
       "      <td>niKP9.PDcNX@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Joseph</td>\n",
       "      <td>Regular</td>\n",
       "      <td>2.02</td>\n",
       "      <td>116000</td>\n",
       "      <td>1974-05-15</td>\n",
       "      <td>China</td>\n",
       "      <td>AOOmV.7nToS@hotmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Richard</td>\n",
       "      <td>Special</td>\n",
       "      <td>1.81</td>\n",
       "      <td>103000</td>\n",
       "      <td>2008-03-20</td>\n",
       "      <td>USA</td>\n",
       "      <td>9GYUe.hp1Np@hotmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Elizabeth</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1.53</td>\n",
       "      <td>62000</td>\n",
       "      <td>1980-11-09</td>\n",
       "      <td>France</td>\n",
       "      <td>Espjq.UqTYO@hotmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Joseph</td>\n",
       "      <td>Special</td>\n",
       "      <td>1.73</td>\n",
       "      <td>123000</td>\n",
       "      <td>1983-10-26</td>\n",
       "      <td>China</td>\n",
       "      <td>hbRcB.aTr4E@hotmail.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Name Category  Height  Salary       Date       Country  \\\n",
       "0    Patricia  Unknown    1.82  129000 1965-10-11           USA   \n",
       "1     Charles  Unknown    1.83  101000 2018-10-02  South Africa   \n",
       "2       Sarah  Regular    1.79   79000 1965-03-02  South Africa   \n",
       "4       Linda  Special    2.04  141000 1959-11-07           USA   \n",
       "5     Jessica  Unknown    1.91  137000 1966-03-14        Brasil   \n",
       "6     William  Unknown    1.82   46000 1975-08-26         China   \n",
       "8      Joseph  Regular    2.02  116000 1974-05-15         China   \n",
       "9     Richard  Special    1.81  103000 2008-03-20           USA   \n",
       "11  Elizabeth  Unknown    1.53   62000 1980-11-09        France   \n",
       "12     Joseph  Special    1.73  123000 1983-10-26         China   \n",
       "\n",
       "                      Email  \n",
       "0   iYpKe.6ZiHz@hotmail.com  \n",
       "1   hcwFo.AYXPZ@hotmail.com  \n",
       "2   oZUD1.7kRFB@hotmail.com  \n",
       "4     8yFow.tGlcK@gmail.com  \n",
       "5     KBKKW.m4AcI@gmail.com  \n",
       "6     niKP9.PDcNX@gmail.com  \n",
       "8   AOOmV.7nToS@hotmail.com  \n",
       "9   9GYUe.hp1Np@hotmail.com  \n",
       "11  Espjq.UqTYO@hotmail.com  \n",
       "12  hbRcB.aTr4E@hotmail.com  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
