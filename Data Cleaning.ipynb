{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_generation import *\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = generate_dataset(length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Category</th>\n",
       "      <th>Height</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Date</th>\n",
       "      <th>Country</th>\n",
       "      <th>Email</th>\n",
       "      <th>Strange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.91</td>\n",
       "      <td>30000</td>\n",
       "      <td>5 1982-1</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>2wPWB.40iuX@gmail.com</td>\n",
       "      <td>H8fPb8Ggbd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>90.0</td>\n",
       "      <td>UNKWN</td>\n",
       "      <td>1.70</td>\n",
       "      <td>90000</td>\n",
       "      <td>11 2016-6</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>Mx3dJ.dLsJF@test.xxx</td>\n",
       "      <td>Al5FACCOV5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Michael</td>\n",
       "      <td>63.0</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1.99</td>\n",
       "      <td>83000</td>\n",
       "      <td>7 1980-17</td>\n",
       "      <td>Fr</td>\n",
       "      <td>2QEKy.zzBH1@laposte.net</td>\n",
       "      <td>eFpkbcKghW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Classic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83000</td>\n",
       "      <td>8 1997-17</td>\n",
       "      <td>USA</td>\n",
       "      <td>ZxYgq.uY3cs@laposte.net</td>\n",
       "      <td>6TBt1eVloK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1.87</td>\n",
       "      <td>39000</td>\n",
       "      <td>8 2016-12</td>\n",
       "      <td>China</td>\n",
       "      <td>zwCAI.7sCxo@gmail.com</td>\n",
       "      <td>kSzyjjWo7J</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  Missing Category  Height  Salary       Date       Country  \\\n",
       "0      NaN      NaN      NaN    1.91   30000   5 1982-1        Brasil   \n",
       "1      NaN     90.0    UNKWN    1.70   90000  11 2016-6  South Africa   \n",
       "2  Michael     63.0  Regular    1.99   83000  7 1980-17            Fr   \n",
       "3      NaN      NaN  Classic     NaN   83000  8 1997-17           USA   \n",
       "4      NaN      NaN  Regular    1.87   39000  8 2016-12         China   \n",
       "\n",
       "                     Email     Strange  \n",
       "0    2wPWB.40iuX@gmail.com  H8fPb8Ggbd  \n",
       "1     Mx3dJ.dLsJF@test.xxx  Al5FACCOV5  \n",
       "2  2QEKy.zzBH1@laposte.net  eFpkbcKghW  \n",
       "3  ZxYgq.uY3cs@laposte.net  6TBt1eVloK  \n",
       "4    zwCAI.7sCxo@gmail.com  kSzyjjWo7J  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1/ Strange feature deletion\n",
    "\n",
    "Sometimes, there are features in your data that seem relatively strange, and in some cases that are really hard to understand or apprehend. They can be useless features, and to avoid wrong interpretations later in your analysis, deleting this strange feature can be an option.\n",
    "\n",
    "In my dataset, I voluntarily created a **Strange** feature, to showcase the ability to prepare your data and continue your analysis on an appropriate perimeter of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Category</th>\n",
       "      <th>Height</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Date</th>\n",
       "      <th>Country</th>\n",
       "      <th>Email</th>\n",
       "      <th>Strange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.91</td>\n",
       "      <td>30000</td>\n",
       "      <td>5 1982-1</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>2wPWB.40iuX@gmail.com</td>\n",
       "      <td>H8fPb8Ggbd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>90.0</td>\n",
       "      <td>UNKWN</td>\n",
       "      <td>1.70</td>\n",
       "      <td>90000</td>\n",
       "      <td>11 2016-6</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>Mx3dJ.dLsJF@test.xxx</td>\n",
       "      <td>Al5FACCOV5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Michael</td>\n",
       "      <td>63.0</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1.99</td>\n",
       "      <td>83000</td>\n",
       "      <td>7 1980-17</td>\n",
       "      <td>Fr</td>\n",
       "      <td>2QEKy.zzBH1@laposte.net</td>\n",
       "      <td>eFpkbcKghW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Classic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83000</td>\n",
       "      <td>8 1997-17</td>\n",
       "      <td>USA</td>\n",
       "      <td>ZxYgq.uY3cs@laposte.net</td>\n",
       "      <td>6TBt1eVloK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1.87</td>\n",
       "      <td>39000</td>\n",
       "      <td>8 2016-12</td>\n",
       "      <td>China</td>\n",
       "      <td>zwCAI.7sCxo@gmail.com</td>\n",
       "      <td>kSzyjjWo7J</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  Missing Category  Height  Salary       Date       Country  \\\n",
       "0      NaN      NaN      NaN    1.91   30000   5 1982-1        Brasil   \n",
       "1      NaN     90.0    UNKWN    1.70   90000  11 2016-6  South Africa   \n",
       "2  Michael     63.0  Regular    1.99   83000  7 1980-17            Fr   \n",
       "3      NaN      NaN  Classic     NaN   83000  8 1997-17           USA   \n",
       "4      NaN      NaN  Regular    1.87   39000  8 2016-12         China   \n",
       "\n",
       "                     Email     Strange  \n",
       "0    2wPWB.40iuX@gmail.com  H8fPb8Ggbd  \n",
       "1     Mx3dJ.dLsJF@test.xxx  Al5FACCOV5  \n",
       "2  2QEKy.zzBH1@laposte.net  eFpkbcKghW  \n",
       "3  ZxYgq.uY3cs@laposte.net  6TBt1eVloK  \n",
       "4    zwCAI.7sCxo@gmail.com  kSzyjjWo7J  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the first few lines of the dataset to get a sense of data\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the \"Useless\" feature of the dataset\n",
    "dataframe = dataframe.drop(['Strange'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Category</th>\n",
       "      <th>Height</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Date</th>\n",
       "      <th>Country</th>\n",
       "      <th>Email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.91</td>\n",
       "      <td>30000</td>\n",
       "      <td>5 1982-1</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>2wPWB.40iuX@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>90.0</td>\n",
       "      <td>UNKWN</td>\n",
       "      <td>1.70</td>\n",
       "      <td>90000</td>\n",
       "      <td>11 2016-6</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>Mx3dJ.dLsJF@test.xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Michael</td>\n",
       "      <td>63.0</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1.99</td>\n",
       "      <td>83000</td>\n",
       "      <td>7 1980-17</td>\n",
       "      <td>Fr</td>\n",
       "      <td>2QEKy.zzBH1@laposte.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Classic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83000</td>\n",
       "      <td>8 1997-17</td>\n",
       "      <td>USA</td>\n",
       "      <td>ZxYgq.uY3cs@laposte.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1.87</td>\n",
       "      <td>39000</td>\n",
       "      <td>8 2016-12</td>\n",
       "      <td>China</td>\n",
       "      <td>zwCAI.7sCxo@gmail.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  Missing Category  Height  Salary       Date       Country  \\\n",
       "0      NaN      NaN      NaN    1.91   30000   5 1982-1        Brasil   \n",
       "1      NaN     90.0    UNKWN    1.70   90000  11 2016-6  South Africa   \n",
       "2  Michael     63.0  Regular    1.99   83000  7 1980-17            Fr   \n",
       "3      NaN      NaN  Classic     NaN   83000  8 1997-17           USA   \n",
       "4      NaN      NaN  Regular    1.87   39000  8 2016-12         China   \n",
       "\n",
       "                     Email  \n",
       "0    2wPWB.40iuX@gmail.com  \n",
       "1     Mx3dJ.dLsJF@test.xxx  \n",
       "2  2QEKy.zzBH1@laposte.net  \n",
       "3  ZxYgq.uY3cs@laposte.net  \n",
       "4    zwCAI.7sCxo@gmail.com  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have another look on the data without the useless feature that has been deleted\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After deleting the `Strange` feature I was not interested in, I just have a look at my dataset to check the proper deletion of this feature, and continue my Data Cleaning process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2/ Missing values as a special category\n",
    "\n",
    "In this part, I will study the different values that take the **Category** feature of my dataset.\n",
    "\n",
    "I quickly detect there are a few values that are taken and that represent a missing or an invalid value for the category. Therefore, I want to treat all these different values as a single and unique representation of the missing value concept : affect them all to the same category that I can myself rename `Unknown`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classic    13\n",
       "Regular    13\n",
       "Special    12\n",
       "UNKWN       4\n",
       "???         3\n",
       "null        3\n",
       "NaN         2\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the different values taken by data for the Category feature\n",
    "dataframe['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace data missing values for the Category feature by a single and dedicated value\n",
    "dataframe['Category'].replace(['NaN', 'null', 'UNKWN', '???'], ['Unknown']*4, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classic    13\n",
       "Regular    13\n",
       "Special    12\n",
       "Unknown    12\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the different values taken by data for the Category feature, after missing category cleaning process\n",
    "dataframe['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having checked my transformed dataset with this single missing value for the Category feature, I will be able to process this feature later on knowing it can take values I had a glance on (`Classic`, `Regular`, `Special`), or the `Unknown` missing value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3/ Fixing spelling mistakes with known correct values\n",
    "\n",
    "There is a **Country** feature in my dataset that contains a few country names, but some of them are sometimes spelled or written in a strange way. That can totally happen in real life when you collect data from multiple sources and these sources do not have the same software/language references.\n",
    "\n",
    "Then, I will try to understand the misspelled values and replace them by a uniformed writting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "China           9\n",
       "USA             8\n",
       "France          8\n",
       "South Africa    7\n",
       "brUsil          5\n",
       "Brasil          4\n",
       "Fr              3\n",
       "SAF             3\n",
       "uSa             2\n",
       "CHinA           1\n",
       "Name: Country, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the different values taken by data for the Country feature\n",
    "dataframe['Country'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the different values that can take the Country feature, there are few ones that misspelled or abstracted, but we can guess the name of the real country behind it. For example, *Fr* probably means *France*, *CHinA* and *uSa* is of course a misspelling, *SAF* in an abstraction of *South Africa* and *brUsil* is totally a mistake in data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace misspelled and erroneous values for the Country feature by a known correct values\n",
    "dataframe['Country'].replace(['SAF', 'Fr', 'CHinA', 'uSa', 'brUsil'],\n",
    "                             ['South Africa', 'France', 'China', 'USA', 'Brasil'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "France          11\n",
       "South Africa    10\n",
       "USA             10\n",
       "China           10\n",
       "Brasil           9\n",
       "Name: Country, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the different values taken by data for the Country feature, after fixing misspelled values\n",
    "dataframe['Country'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this spellchecking and fixing step of the Data Cleaning process, we now clearly see the different countries involved in the dataset, with no surprising or confusing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4/ Mean filling for missing values\n",
    "\n",
    "The **Height** feature of the dataset miss a few values, but not a large amount. In order to analyse the data without deleting too much information, it can be clever in some cases to replace missing values in numerical features by the mean of this feature.\n",
    "\n",
    "There are not too much outliers in this feature, so replacing missing values by the mean can be a good choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height feature has 7 null values and 43 not null values !\n"
     ]
    }
   ],
   "source": [
    "# Check the proportion of null values in the Height feature\n",
    "height_null_values = sum(dataframe['Height'].isnull() == True)\n",
    "height_notnull_values = sum(dataframe['Height'].isnull() == False)\n",
    "print(\"Height feature has {} null values and {} not null values !\".format(height_null_values, height_notnull_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean value of the Height feature in the dataset, and replace missing values with it\n",
    "height_mean_value = round(dataframe[\"Height\"].mean(), 2)\n",
    "dataframe['Height'].fillna(height_mean_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height feature has 0 null values and 50 not null values !\n"
     ]
    }
   ],
   "source": [
    "# Check the proportion of null values in the Height feature after mean filling\n",
    "height_null_values = sum(dataframe['Height'].isnull() == True)\n",
    "height_notnull_values = sum(dataframe['Height'].isnull() == False)\n",
    "print(\"Height feature has {} null values and {} not null values !\".format(height_null_values, height_notnull_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the `Height` feature missing values have been replaced with the mean value, you shall heterogeneous set of values on this feature to do further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5/ Useless observations deletion\n",
    "\n",
    "The **Name** feature, in my dataset example, serves as an identifier of each observation. We can face cases with real world data, where these identifiers are not filled. There are a bunch of data available, but we cannot link them to a defined indentifier, a specific object or individual.\n",
    "\n",
    "This generally means whathever the analysis you will make on your data, you will be blocked at some point for some cases where you need to identify a data point. Thus, it is sometimes useful to delete these points for some specific analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name feature has 20 null values and 30 not null values !\n"
     ]
    }
   ],
   "source": [
    "# Check the proportion of null values in the Name feature\n",
    "name_null_values = sum(dataframe['Name'].isnull() == True)\n",
    "name_notnull_values = sum(dataframe['Name'].isnull() == False)\n",
    "print(\"Name feature has {} null values and {} not null values !\".format(name_null_values, name_notnull_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete observations where Name feature value is missing\n",
    "dataframe = dataframe.dropna(subset=['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name feature has 0 null values and 30 not null values !\n"
     ]
    }
   ],
   "source": [
    "# Check the proportion of null values in the Name feature after mean filling\n",
    "name_null_values = sum(dataframe['Name'].isnull() == True)\n",
    "name_notnull_values = sum(dataframe['Name'].isnull() == False)\n",
    "print(\"Name feature has {} null values and {} not null values !\".format(name_null_values, name_notnull_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deleting observations that have missing values for the `Name` feature shall reduce your dataset size, but help you to do identification and relationships analysis easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6/ Useless feature deletion\n",
    "\n",
    "There is a **Missing** feature in my dataset that, like its name indicates, misses a large amount of data. When a feature lacks information on the majority of the data points, this means this feature does not really bring something interesting to the analysis done later on.\n",
    "\n",
    "In this case, this feature is considered useless and better be deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Category</th>\n",
       "      <th>Height</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Date</th>\n",
       "      <th>Country</th>\n",
       "      <th>Email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Michael</td>\n",
       "      <td>63.0</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1.99</td>\n",
       "      <td>83000</td>\n",
       "      <td>7 1980-17</td>\n",
       "      <td>France</td>\n",
       "      <td>2QEKy.zzBH1@laposte.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Elizabeth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1.53</td>\n",
       "      <td>43000</td>\n",
       "      <td>8 2008-16</td>\n",
       "      <td>France</td>\n",
       "      <td>ZLP99.nR2JJ@laposte.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mary</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Classic</td>\n",
       "      <td>1.75</td>\n",
       "      <td>93000</td>\n",
       "      <td>8 1950-11</td>\n",
       "      <td>France</td>\n",
       "      <td>tYKV1.wgJl2@darkmagic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>William</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Classic</td>\n",
       "      <td>1.75</td>\n",
       "      <td>136000</td>\n",
       "      <td>6 1989-29</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>y7IR0.VIJWN@hotmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>David</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Classic</td>\n",
       "      <td>1.79</td>\n",
       "      <td>94000</td>\n",
       "      <td>6 2007-3</td>\n",
       "      <td>USA</td>\n",
       "      <td>Sec91.caD2U@hotmail.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name  Missing Category  Height  Salary       Date       Country  \\\n",
       "2    Michael     63.0  Regular    1.99   83000  7 1980-17        France   \n",
       "5  Elizabeth      NaN  Regular    1.53   43000  8 2008-16        France   \n",
       "6       Mary      4.0  Classic    1.75   93000  8 1950-11        France   \n",
       "7    William      NaN  Classic    1.75  136000  6 1989-29  South Africa   \n",
       "8      David      NaN  Classic    1.79   94000   6 2007-3           USA   \n",
       "\n",
       "                     Email  \n",
       "2  2QEKy.zzBH1@laposte.net  \n",
       "5  ZLP99.nR2JJ@laposte.net  \n",
       "6    tYKV1.wgJl2@darkmagic  \n",
       "7  y7IR0.VIJWN@hotmail.com  \n",
       "8  Sec91.caD2U@hotmail.com  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the few first lines of the dataset and especially the Missing feature values\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the \"Missing\" feature of the dataset\n",
    "dataframe = dataframe.drop(['Missing'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Height</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Date</th>\n",
       "      <th>Country</th>\n",
       "      <th>Email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Michael</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1.99</td>\n",
       "      <td>83000</td>\n",
       "      <td>7 1980-17</td>\n",
       "      <td>France</td>\n",
       "      <td>2QEKy.zzBH1@laposte.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Elizabeth</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1.53</td>\n",
       "      <td>43000</td>\n",
       "      <td>8 2008-16</td>\n",
       "      <td>France</td>\n",
       "      <td>ZLP99.nR2JJ@laposte.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mary</td>\n",
       "      <td>Classic</td>\n",
       "      <td>1.75</td>\n",
       "      <td>93000</td>\n",
       "      <td>8 1950-11</td>\n",
       "      <td>France</td>\n",
       "      <td>tYKV1.wgJl2@darkmagic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>William</td>\n",
       "      <td>Classic</td>\n",
       "      <td>1.75</td>\n",
       "      <td>136000</td>\n",
       "      <td>6 1989-29</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>y7IR0.VIJWN@hotmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>David</td>\n",
       "      <td>Classic</td>\n",
       "      <td>1.79</td>\n",
       "      <td>94000</td>\n",
       "      <td>6 2007-3</td>\n",
       "      <td>USA</td>\n",
       "      <td>Sec91.caD2U@hotmail.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name Category  Height  Salary       Date       Country  \\\n",
       "2    Michael  Regular    1.99   83000  7 1980-17        France   \n",
       "5  Elizabeth  Regular    1.53   43000  8 2008-16        France   \n",
       "6       Mary  Classic    1.75   93000  8 1950-11        France   \n",
       "7    William  Classic    1.75  136000  6 1989-29  South Africa   \n",
       "8      David  Classic    1.79   94000   6 2007-3           USA   \n",
       "\n",
       "                     Email  \n",
       "2  2QEKy.zzBH1@laposte.net  \n",
       "5  ZLP99.nR2JJ@laposte.net  \n",
       "6    tYKV1.wgJl2@darkmagic  \n",
       "7  y7IR0.VIJWN@hotmail.com  \n",
       "8  Sec91.caD2U@hotmail.com  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look back at the dataset with Missing feature deleted\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a useless feature is deleted, models and statistics used on the dataset get more precise because they are not perturbated anymore by a lot of incorrected or missing data. It is really important to focus solely on data that has interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7/ Median filling for erroneous values\n",
    "\n",
    "The **Salary** feature of the dataset has a few values that do not seem plausible, they may be an error. When data is missing or is irrelevant in a numerical feature, and this numerical feature has potentially large outliers in it, replacing the data by the median instead of the mean can be more appropriate.\n",
    "\n",
    "I voluntarily genertated great outliers, and I want to show how we can replace them by the median of the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salary feature : max=499000, min=37000, mean=120300, median=104000\n"
     ]
    }
   ],
   "source": [
    "max_salary = max(dataframe['Salary'])\n",
    "min_salary = min(dataframe['Salary'])\n",
    "mean_salary = math.ceil(round(dataframe['Salary'].mean(), 0))\n",
    "median_salary = math.ceil(dataframe['Salary'].median())\n",
    "print(\"Salary feature : max={}, min={}, mean={}, median={}\".format(max_salary, min_salary, mean_salary, median_salary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean value of the Height feature in the dataset, and replace missing values with it\n",
    "max_salary_no_outlier = mean_salary = math.ceil(round(dataframe['Salary'].mean() * 2.5, 0))\n",
    "dataframe = dataframe.reset_index()\n",
    "high_salary_indices = dataframe[(dataframe[\"Salary\"] > max_salary_no_outlier)].index\n",
    "dataframe.iloc[high_salary_indices, [dataframe.columns.get_loc('Salary')]] = median_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salary feature : max=142000, min=37000, mean=94900, median=103500\n"
     ]
    }
   ],
   "source": [
    "max_salary = max(dataframe[\"Salary\"])\n",
    "min_salary = min(dataframe[\"Salary\"])\n",
    "mean_salary = math.ceil(round(dataframe[\"Salary\"].mean(), 0))\n",
    "median_salary = math.ceil(dataframe[\"Salary\"].median())\n",
    "print(\"Salary feature : max={}, min={}, mean={}, median={}\".format(max_salary, min_salary, mean_salary, median_salary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the `Salary` feature outliers have been replaced with the median value, further analysis shall be more precise and interesting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8/ Dates wrong formatting\n",
    "\n",
    "There are often dates type features in datasets, in mine we can find the evident **Date** feature. Dates features often present bad formatting according countries, times, or sources where we got your data from. It is vital to clean dates features especially on a uniform form, throughout your feature, and throughout your entire dataset.\n",
    "\n",
    "I invented a confusing representation of dates in my artificially generated dataset, that I need to cleanse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Height</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Date</th>\n",
       "      <th>Country</th>\n",
       "      <th>Email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Michael</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1.99</td>\n",
       "      <td>83000</td>\n",
       "      <td>7 1980-17</td>\n",
       "      <td>France</td>\n",
       "      <td>2QEKy.zzBH1@laposte.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Elizabeth</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1.53</td>\n",
       "      <td>43000</td>\n",
       "      <td>8 2008-16</td>\n",
       "      <td>France</td>\n",
       "      <td>ZLP99.nR2JJ@laposte.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>Mary</td>\n",
       "      <td>Classic</td>\n",
       "      <td>1.75</td>\n",
       "      <td>93000</td>\n",
       "      <td>8 1950-11</td>\n",
       "      <td>France</td>\n",
       "      <td>tYKV1.wgJl2@darkmagic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>William</td>\n",
       "      <td>Classic</td>\n",
       "      <td>1.75</td>\n",
       "      <td>136000</td>\n",
       "      <td>6 1989-29</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>y7IR0.VIJWN@hotmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>David</td>\n",
       "      <td>Classic</td>\n",
       "      <td>1.79</td>\n",
       "      <td>94000</td>\n",
       "      <td>6 2007-3</td>\n",
       "      <td>USA</td>\n",
       "      <td>Sec91.caD2U@hotmail.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       Name Category  Height  Salary       Date       Country  \\\n",
       "0      2    Michael  Regular    1.99   83000  7 1980-17        France   \n",
       "1      5  Elizabeth  Regular    1.53   43000  8 2008-16        France   \n",
       "2      6       Mary  Classic    1.75   93000  8 1950-11        France   \n",
       "3      7    William  Classic    1.75  136000  6 1989-29  South Africa   \n",
       "4      8      David  Classic    1.79   94000   6 2007-3           USA   \n",
       "\n",
       "                     Email  \n",
       "0  2QEKy.zzBH1@laposte.net  \n",
       "1  ZLP99.nR2JJ@laposte.net  \n",
       "2    tYKV1.wgJl2@darkmagic  \n",
       "3  y7IR0.VIJWN@hotmail.com  \n",
       "4  Sec91.caD2U@hotmail.com  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first few lines of the dataset, to have a look on the dates format of my Date feature\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the whole feature into a real datetime format, precising the data input format provided\n",
    "dataframe['Date'] = pd.to_datetime(dataframe['Date'], format=\"%m %Y-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Height</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Date</th>\n",
       "      <th>Country</th>\n",
       "      <th>Email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Michael</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1.99</td>\n",
       "      <td>83000</td>\n",
       "      <td>1980-07-17</td>\n",
       "      <td>France</td>\n",
       "      <td>2QEKy.zzBH1@laposte.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Elizabeth</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1.53</td>\n",
       "      <td>43000</td>\n",
       "      <td>2008-08-16</td>\n",
       "      <td>France</td>\n",
       "      <td>ZLP99.nR2JJ@laposte.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>Mary</td>\n",
       "      <td>Classic</td>\n",
       "      <td>1.75</td>\n",
       "      <td>93000</td>\n",
       "      <td>1950-08-11</td>\n",
       "      <td>France</td>\n",
       "      <td>tYKV1.wgJl2@darkmagic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>William</td>\n",
       "      <td>Classic</td>\n",
       "      <td>1.75</td>\n",
       "      <td>136000</td>\n",
       "      <td>1989-06-29</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>y7IR0.VIJWN@hotmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>David</td>\n",
       "      <td>Classic</td>\n",
       "      <td>1.79</td>\n",
       "      <td>94000</td>\n",
       "      <td>2007-06-03</td>\n",
       "      <td>USA</td>\n",
       "      <td>Sec91.caD2U@hotmail.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       Name Category  Height  Salary       Date       Country  \\\n",
       "0      2    Michael  Regular    1.99   83000 1980-07-17        France   \n",
       "1      5  Elizabeth  Regular    1.53   43000 2008-08-16        France   \n",
       "2      6       Mary  Classic    1.75   93000 1950-08-11        France   \n",
       "3      7    William  Classic    1.75  136000 1989-06-29  South Africa   \n",
       "4      8      David  Classic    1.79   94000 2007-06-03           USA   \n",
       "\n",
       "                     Email  \n",
       "0  2QEKy.zzBH1@laposte.net  \n",
       "1  ZLP99.nR2JJ@laposte.net  \n",
       "2    tYKV1.wgJl2@darkmagic  \n",
       "3  y7IR0.VIJWN@hotmail.com  \n",
       "4  Sec91.caD2U@hotmail.com  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the good transformation of dates format in the dataset\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now my dates format have been cleansed in the `Date` feature, we should have a better view of dates in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9/ Strange obervations deletion\n",
    "\n",
    "On some features of a dataset, strange values may sometimes appear, and it is difficult to understand whether it is a normal value or a harmful, confusing and non intentional value (that could have been introduced in the process). In the case of my **Email** feature, a very strange or non comprehensive email suffix can mean a lot of things.\n",
    "\n",
    "In this context, I will show how to delete these observations to protect the dataset and run only meaningfull analysis on verified individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hotmail.com    10\n",
       "gmail.com      10\n",
       "laposte.net     8\n",
       "darkmagic       2\n",
       "Name: Suffices, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check all the existing email suffices in the initial dataset\n",
    "email_suffices = pd.DataFrame({\"Suffices\": dataframe[\"Email\"].str.split(\"@\", expand=True)[1]})\n",
    "email_suffices[\"Suffices\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve indices of observations with harmful email suffices and delete them\n",
    "harmful_email_indices = email_suffices[(email_suffices['Suffices'] == 'darkmagic')\n",
    "                                       | (email_suffices['Suffices'] == 'test.xxx')\n",
    "                                       | (email_suffices['Suffices'] == 'weneverknow.com')].index\n",
    "dataframe.drop(harmful_email_indices, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether the deletion of observations with harmful email suffices worked \n",
    "email_suffices = pd.DataFrame({\"Suffices\": dataframe[\"Email\"].str.split(\"@\", expand=True)[1]})\n",
    "email_suffices[\"Suffices\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the few potentially harmful `Email` addresses have been deleted, we are narrowing our individuals with interesting data and trustable information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
